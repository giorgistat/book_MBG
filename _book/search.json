[
  {
    "objectID": "01_intro.html#objectives-of-this-book",
    "href": "01_intro.html#objectives-of-this-book",
    "title": "1  Introduction",
    "section": "1.1 Objectives of this book",
    "text": "1.1 Objectives of this book\nThe overall aim of this book is to provide you with the skills to perform a geostatistical analysis of a data-set using the R software environment. As you work your way through the book, you will learn to:\n\nexplore geostatistical data-sets using graphical procedures and summary statistics;\nformulate and fit geostatistical models using the maximum likelihood estimation method;\ncarry out prediction of health outcomes at different spatial scales;\nvisualize and interpret the results from geostatistical models;\nmodel the relationships between spatially referenced risk factors and the health outcome of interest;\nvalidate the assumptions of geostatistical models and assess their predictive performance.\n\nAlthough the focus of this book is on public health, the statistical ideas, as well as the software used, can also be applied for the analysis of geostatistical data-sets arising from other scientific fields."
  },
  {
    "objectID": "01_intro.html#pre-requisites-for-using-this-book",
    "href": "01_intro.html#pre-requisites-for-using-this-book",
    "title": "1  Introduction",
    "section": "1.2 Pre-requisites for using this book",
    "text": "1.2 Pre-requisites for using this book\nTo effectively understand and use the material presented in this book, it is expected that you should possess prior knowledge of basic probability theory, foundational topics in statistical modelling and R programming. Below we provide a more detailed explanation of the pre-requisites for each of these three fields.\n\n1.2.1 Topics in probability\nBasics probability theory is important to fully understand the content of this book. In particular, you should have knowledge of: the general definition and properties of continuous and discrete distribution; how the describe the properties of probability distributions through their mean, variance and skeweness; the concepts of stochastic dependence and correaltion; the distinction between marginal and conditional distributions; the basic properties of the Gaussian, Binomial and Poisson distributions; the definition and properties of the multivariate Gaussian distribution. The redear can find an extensive explanation and illustrations with examples of all these topics in Ross (2013).\n\n\n1.2.2 Topics in statistics\nLikelihood-based inference (whether frequensist or Bayesian) provides the theoretical bedrock for the estimation of almost any statistical model. In this book will focus on maximum likelihood estimation methods of inference. Extensive use of the notions of point and interval estimates obtained using the maximum likelihood estimation methods will be made through the book. Recommended readings include chapters 1, 2 and 4 of Pawitan (2001).\nGood prior knowledge of Generalized linear models (GLMs) is essential, as the geostatistical modelling framework builds on these as an extension. Before embarking on the use of this book, we thus encourage you to review the basic theory of GLMs and, in particular, how these are applied and interpreted. In this book, we will cover examples that will model continuously measured outcomes and counts. Hence, good understanding of linear regression modelling and modelling of counts data using Binomial and Poisson regression should be the main focus of the review. For comprehensive overview of GLMs and their implementation in R, we refer you to Dobson and Barnett (2008).\n\n\n1.2.3 Topics in R programming\nAlthough this book does not require to possess advanced skills in R programming, it is important you have good knowledge in the following topics: creation and manipulation of vectors and matrices; logical vectors; character vectors; handling of lists and data frame objects; reading data into R; graphical procedures. A very large amount of freely available material covering these topics can be found online. Our recommendation is to start from the manual “An introduction to R” of the Comprehensive R Archive Network available at this link, available at R manual."
  },
  {
    "objectID": "01_intro.html#obtaining-and-running-the-r-packages",
    "href": "01_intro.html#obtaining-and-running-the-r-packages",
    "title": "1  Introduction",
    "section": "1.3 Obtaining and running the R packages",
    "text": "1.3 Obtaining and running the R packages\nIt is advised that you obtain the latest 64-bit version of R in order to run the R code of this book. To install R, go to the R website, where you can download the installer packages for Windows and Mac, and find instructions for Linux, using binary files.\n\nWindows\nMac\nLinux\n\nThe list of the R packages used in this book is provided in Table 1.1.\n\n\nTable 1.1: List of the R packages that will be used in the book with a description of their use in the data analysis. The packages marked by (E) are essential for the geostatistical analysis. Those instead marked by (R) are recommended and can be helpful to overcome issues as described under the column “Used for”.\n\n\n\n\n\n\nR packages\nUsed for\n\n\n\n\nRiskMap (E)\nEstimating of geostatistical models and spatial prediction\n\n\nsf (E)\nHandling of spatial data in R\n\n\nterra (E)\nHandling of raster files in R\n\n\nggplot2 (E)\nCreating maps and exploratory plots\n\n\ncrsuggest (R)\nGuessing a coordinate reference systems when unknown\n\n\n\n\nTo install packages in R for the first time, you can use the command install.packages in the R console, as shown below for the RiskMap package.\n\ninstall.packages(\"RiskMap\")"
  },
  {
    "objectID": "01_intro.html#sec-examples-ch1",
    "href": "01_intro.html#sec-examples-ch1",
    "title": "1  Introduction",
    "section": "1.4 Data-sets used in the book",
    "text": "1.4 Data-sets used in the book\nThe geostatistical data-sets described in this section will be used throughout the book to illustrate the use of the R packages mentioned in the previous sections.\nEach of the examples data-sets can be loaded from the RiskMap package, using the command\n\ndata(NAME_OF_THE_DATASET)\n\nwhere in place of NAME_OF_THE_DATASET you should type of the name of one of the data-sets listed in Table 1.2.\n\n\nTable 1.2: List of data-sets available from the RiskMap package. Data-sets listed as “Example” are used throughout the book to illustrate the use of R functions. Data-sets listed as “Case study” are analysed in Chapter 6.\n\n\n\n\n\n\n\nNames of the data-set\nShort description\nUsed in this book as\n\n\n\n\ngalicia\nLead concentration m from moss samples collected in Galicia, Northern Spain\nExample\n\n\nliberia\nPrevalence data on river-blindness from Liberia\nExample\n\n\nmalkenya\nMalaria prevalence data from a community and school survey conducted in Western Kenya\nExample\n\n\nitaly_sim\nSimulated geostatistical data-set within the Italian national boundaries\nExample\n\n\nmalnutrition\nData on stunting among children in Ghana\nCase study\n\n\n\n\n\n1.4.1 Lead concentration in Galicia\n\n\n\n\n\n\nFigure 1.1: Data on the meausred lead concentration (in micrograms per gram dry weight) in moss samples collected in Galicia, North-West of Spain.\n\n\n\nLead is a heavy metal which, in high concentrations, can cause chronic damage to living organisms over a long period of time. For this reason its spread and source must be regularly monitored. To assess the extent of the contamination in an area, measurements of lead are often taken from plants. The data here considered (Figure 1.1) consist of 132 locations of moss samples collected in 2000, in and around Galicia, a region in the North-Western part of Spain. One of the objectives of this survey was to establish the spatial pattern of lead concentration in Galicia so as to better identify possible sources of contamination; fore more information, see Fernández, Rey, and Carballeira (2000).\nIn this case, geostatistical modelling can be used to predict the lead concentration across Galicia and allows to disentangle variation which is purely random, possibly due to measurement error, and genuine spatial variation, which is our main object of interest.\nThis data-set will be used in this book to show how to carry out the spatial analysis of continuously measured variables using linear geostatistical models.\n\n\n1.4.2 River-blindness in Liberia\n\n\n\n\n\n\nFigure 1.2: River-blindness data from a cross-sectional survey carried out in Liberia.\n\n\n\nIn low-resource settings, where disease registries are typically absent, cross-sectional surveys are an essential monitoring tool that enables the estimation of the disease burden in a population of interest. The data considered in this example (Figure 1.2) have been collected as part of an Africa-wide initiative called the Rapid Epidemiological Mapping of Onchocerchiasis (REMO) carried out in 2011 in 20 African countries (Zouré et al. 2014). The goal of REMO is to identify areas where river-blindness (or onchocerchiasis), a disease transmitted by black flies who breed along fast flowing rivers, is still a public health problem. In this context, it is especially of interest to identify communities with a prevalence above 20% and for treatment is urgently needed.\nIn this book, we will use data collected from Liberia to model nodule prevalence, which is based on a alternative and cheaper diagnostic technique for river-blindness. In the analysis of this data-set, we will illustrate how to formulate and fit Binomial geostatistical models, and how these can be used to predict prevalence within a region of interest.\n\n\n1.4.3 Malaria in the Western Kenyan Highlands\n\n\n\n\n\n\nFigure 1.3: Malaria prevalence data from a cross-sectional survey carried out in Nyanza Province, in the Western Highlands of Kenya.\n\n\n\nMalaria is one of deadliest diseases that affects populations living in tropical and subtropical countries. It is caused by a parasite of the genus Plasmodium which is transmitted through the infectious bite of female Anopheles mosquitoes. In the following chapters, we shall analyse a data-set from a cross-sectional community survey carried out in July 2010 in Nyanza Province, in the Western Highlands of Kenya (Stevenson 2013).\nWhat distinguishes this from the other examples data-sets is that the data contain both individual-level and household-level information. The outcome of interest is the result from a rapid diagnostic test for malaria which. In the book, we will illustrate how to account for the the hierarchical structure of the data and the binary nature of the outcome at each of the stages of the geostatistical analysis.\n\n\n1.4.4 Anopheles gambiae mosquitoes in Southern Cameroon\n\n\n\n\n\n\nFigure 1.4: Map of the collected number of Anopheles gambiae mosquitoes in an area of Southern Cameroon.\n\n\n\nIn studies of vector-borne and zoonotic diseases, understanding of the vector distribution can help to better guide the decision-making process for the implementation, monitoring and evaluation of control programmes. Anopheles gambiae mosquitoes are one of the main vectors for malaria transmission in sub-Saharan Africa. Their distribution over space is affected by several environmental and climatic factors, including temperature, humidity and vegetation.\nThe data-set on mosquitoes (Figure 1.4) that will use in the book consists of a sub-set taken from a large database (Tene Fossog et al. 2015). This was assembled in order to understand how the environment affects the distribution of different species of Anopheles mosquitoes in sub-Saharan Africa. This example data-set will be used to illustrate the application of Poisson geostatistical models for mapping mosquitoes abundance.\n\n\n1.4.5 Simulated-dataset"
  },
  {
    "objectID": "02_handling-spatial-data.html#importing-and-processing-spatial-data-in-r",
    "href": "02_handling-spatial-data.html#importing-and-processing-spatial-data-in-r",
    "title": "2  Handling of spatial data in R",
    "section": "2.1 Importing and processing spatial data in R",
    "text": "2.1 Importing and processing spatial data in R"
  },
  {
    "objectID": "02_handling-spatial-data.html#visualizing-geostatistical-data",
    "href": "02_handling-spatial-data.html#visualizing-geostatistical-data",
    "title": "2  Handling of spatial data in R",
    "section": "2.2 Visualizing geostatistical data",
    "text": "2.2 Visualizing geostatistical data"
  },
  {
    "objectID": "02_handling-spatial-data.html#section",
    "href": "02_handling-spatial-data.html#section",
    "title": "2  Handling of spatial data in R",
    "section": "2.3 ",
    "text": "2.3"
  },
  {
    "objectID": "03_model-fitting.html#list-of-the-main-functions-used-in-the-chapter",
    "href": "03_model-fitting.html#list-of-the-main-functions-used-in-the-chapter",
    "title": "3  Model formulation and parameter estimation",
    "section": "List of the main functions used in the chapter",
    "text": "List of the main functions used in the chapter\n\n\n\n\n\n\n\n\nFunction\nR Package\nUsed for\n\n\n\n\nlmer\nlme4\nFitting linear mixed models\n\n\nglmer\nlme4\nFitting generalized linear mixed models\n\n\nglgm\nRiskMap\nFitting generalized linear mixed models\n\n\ns_variogram\nRiskMap\nComputing the empirical variogram and carrying out permutation test for spatial independence"
  },
  {
    "objectID": "03_model-fitting.html#exploratory-analysis",
    "href": "03_model-fitting.html#exploratory-analysis",
    "title": "3  Model formulation and parameter estimation",
    "section": "3.1 Exploratory analysis",
    "text": "3.1 Exploratory analysis\nAs illustrated in Figure 1.8, exploratory analysis is the first step that should be carried out in a statistical analysis. This stage is essential to inform how covariates should be introduced in the model and, in our case, whether the variation unexplained by those covariates exhibits spatial correlation.\nIn the exploratory analysis of count data, we will also look at how overdispersion, which is a necessary, though not sufficient, condition for residual spatial correlation.\n\n3.1.1 Exploring associations with risk factors using count data\nAssessment of the association between the health outcome of interest and non-categorical (i.e. continuous) risk factors can be carried using graphical tools, such scatter plots. The graphical inspection of the empirical association between the outcome and the covariates is especially useful to identify non-linear patterns in the relationship which should then be accounted for in the model formulation.\nIn this section, we look more closely at the case when the observed outcome is a count which requires a different treatment from continuously measured outcomes, which are generally covered by most statistics textbooks (see, for example, Chapter 1 of Weisberg (2014)).\n\n3.1.1.1 When the outcome is an aggregated count\nLet us first consider the example of the river-blindness data in Liberia (Section 1.4.2), and examine the association between prevalence and elevation. We first generate a plot of the prevalence against the measured elevation at each of the sample locations\n\n## Linking to GEOS 3.10.2, GDAL 3.4.3, PROJ 8.2.1; sf_use_s2() is TRUE\n\n\nliberia$prev &lt;- liberia$npos/liberia$ntest\n\nggplot(liberia, aes(x = elevation, y = prev)) + geom_point() +\n  labs(x=\"Elevation (meters)\",y=\"Prevalence\")\n\n\n\n\nFigure 3.1: Scatter plot of the empirical prevalence for river-blindess against elevation, measured in meters.\n\n\n\n\nThe plot shown in Figure 3.1 shows that, as elevation increases from 0 to around 150 meters, prevalence rapidly increases to around 0.25 and, for larger values in elevation than 150 meters, the relationship levels off. This begs the question of how we can account for this in a regression model. To answer this question rigorously, however, the plot in Figure 3.1 cannot be used. This is because, when the modelled outcome is a bounded Binomial count, regression relationships are specified on the logit-transformed prevalence (log-odds) scale; see Table 1.3 in Section Section 1.5 . To explore regression relationships in the case of prevalence data, it is convenient to use the so-called empirical logit in place of the empirical prevalence. The empirical logit is defined as\n\\[\nl_{i} = \\log\\left\\{\\frac{y_i + 1/2}{n_i - y_i + 1/2}\\right\\}\n\\tag{3.1}\\]\nwhere \\(y_i\\) are the number of individuals who tested positive for riverblindness and \\(n_i\\) is the total number of people tested at a location. The reason for using the empirical logit, rather than the standard logit transformation applied directly to the empirical prevalence, is that it allows to generate finite values for empirical prevalence values of 0 and 1, for which the standard logit transformation is not defined.\n\n# The empirical logit\nliberia$elogit &lt;- log((liberia$npos+0.5)/\n                      (liberia$ntest-liberia$npos+0.5))\n\nggplot(liberia, aes(x = elevation, y = elogit)) + geom_point() +\n  \n  # Adding a smoothing spline\n  labs(x=\"Elevation (meters)\",y=\"Empirical logit\") +\n  stat_smooth(method = \"gam\", formula = y ~ s(x),se=FALSE)+\n  \n  # Adding linear regression fit with log-transformed elevation\n  stat_smooth(method = \"lm\", formula = y ~ log(x),\n              col=\"green\",lty=\"dashed\",se=FALSE) +\n\n  # Adding linear regression fit with change point in 150 meters\n  stat_smooth(method = \"lm\", formula = y ~ x + pmax(x-150, 0),\n              col=\"red\",lty=\"dashed\",se=FALSE) \n  \n\n\n\n\nFigure 3.2: Scatter plot of the empirical prevalence for river-blindess against elevation, measured in meters.\n\n\n\n\nFigure 3.2 shows the scatter plot of the empirical logit against elevation. In this plot, we have also added three lines though the stat_smooth from the ggplot2 package. Using this function, we first pass the term gam to method to add a penalized smoothing spline (Hastie, Tibshirani, and Friedman 2001), represented by the blue solid line. The smoothing spline allows us to better discern how the type of relationship and how to best capture it using a standard regression approach. As er can see from Figure 3.2, the smoothing spline corroborates our initial observation of a positive relationship up to about 150 meters, followed by a plateau.\nTo capture this non-linear relationship, we can use the two following approaches. The first is based on a simple log-transformation of elevation and is represented in Figure 3.2 by the green line. If were to express this relationship using a standard Binomial regression model, this would take the form \\[\n\\log\\left\\{\\frac{p(x_i)}{1-p(x_i)}\\right\\} = \\beta_0 + \\beta_1 \\log\\{e(x_i)\\}\n\\tag{3.2}\\] where \\(p(x_i)\\) and \\(e(x_i)\\) are the river-blindness prevalence and elevation at sampled location \\(x_i\\), respectively.\nAlternatively, the non-linear effect of elevation on prevalence could be captured using a linear spline. Put in simple terms, we want to fit a linear regression model that allows for a change in slope above 150 meters. Formally, this is expressed in a Binomial regression model as \\[\n\\log\\left\\{\\frac{p(x_i)}{1-p(x_i)}\\right\\} = \\beta_0 + \\beta_1 e(x_i) + \\beta_{2} \\max\\{e(x_i)-150, 0\\}.\n\\tag{3.3}\\] Based on the equation above, the effect of elevation below 150 meters is quantified by the parameter \\(\\beta_1\\). Above 150 meters, instead, the effect of elevation becomes \\(\\beta_1 + \\beta_2\\). Note that the function pmax (and not the standard base function max) should be used in R when the computation of the maximum between a scalar value and each of the components of a numeric vector is required.\nBefore proceeding further, it is important to explain the differences between the use of the logarithmic transformation (Equation 3.2) and the linear spline (Equation 3.3). We observe that both curves provide a similar fit to the data, with larger differences observed for larger values in elevation, where the log-transformed elevation models yields larger values for the predicted prevalence. This also suggests that if we were to extrapolate the predictions beyond 600 meters in elevation the implied pattern by the model with the log-transformed elevation would predict an increasingly larger elevation, which is unrealistic, since the fly that transmits the diseases cannot breed at those altitudes. The linear spline model instead would generate predictions that would be very similar to those observed between 150 and 600 meters. From this point view, the linear spline model would thus have more scientific validity than the other model. However, which of the two approaches should be chosen to model the effect of elevation is a question that closely depends on the research question to be addressed.\nIf the interest of the study was in better understanding the association between elevation and prevalence, the linear spline model does not only provide a more credible explanation but also its regression parameters can be more easily interpreted. In fact, for a unit increase in elevation, the multiplicative change in the odds for river-blindness is \\(\\exp\\{\\beta_1\\}\\), if elevation is below 150 meters, and \\(\\exp\\{\\beta_1+\\beta_2\\}\\), if elevation is above 150 meters. When instead we use the log-transformed elevation, the interpretation of \\(\\beta_1\\) in Equation 3.2 is slightly more complicated, as it is based on the multiplicative increase in elevation by the same amount given by the base of the algorithm, which is about \\(e \\approx 2.718\\)1. To avoid this, one could rescale the regression coefficient as, for example, \\(\\beta_1/\\log_{2}(e)\\) which would be interpreted as the multiplicative change in the odds for river-blindness for a doubling in elevation. However, a doubling in elevation is less meaningful when considering larger values of elevation.\nWhen the goal of statistical analysis is instead in developing a predictive model for the outcome of interest, the explanatory power and interpretability of the model may be of less concern. For this reason, the model with the log-transformed model could be preferred over the model with the linear spline, if it shown to yield more predictive power. We will come back to this point again in Chapter 5, where will show how to assess and compare the predictive performance of different geostatistical models.\nThe other type of aggregated count data that we consider are unbounded counts. The Anopheles mosquitoes data-set (Section 1.4.4) is an example of this, since there is no upper limit to the number of mosquitoes that can be trapped at a location. Let us consider the covariate represented by elevation. In this case, the simplest model that can be used to analyse the data is a Poisson regression, where the linear predictor is defined on the log of the mean number of mosquitoes (Table 1.3). Hence, exploratory plots for the association with covariates should be generated using the log transformed counts of mosquitoes. In this instance, to avoid taking the log of zero, we can add 1 to the reported counts, if required. The variable of the An.gambiae in the anopheles data-set does not contain any 0, hence we simply apply the log tranformation without adding 1.\n\nanopheles$log_counts &lt;- log(anopheles$An.gambiae)\nggplot(anopheles, aes(x = elevation, y = log_counts)) + geom_point() +\n  \n  # Adding a smoothing spline\n  labs(x=\"Elevation (meters)\",y=\"Log number of An. gambiae mosquitoes\") +\n  stat_smooth(method = \"lm\", formula = y ~ x, se=FALSE)\n\n\n\n\nFigure 3.3: Scatter plot of the log tranformed number of Anopheles gambiae mosquitoes against elevation, measured in meters. The blue line is generated using the least squares fit.\n\n\n\n\nThe scatter plot of Figure 3.3 shows that there is a negative, though weak, association, with the average number of mosquitoes decreasing for increasing elevation. In this instance, the assumption of a linear relationship with elevation would be a reasonable choice.\n\n\n3.1.1.2 When the outcome is an invidual-level binary indicator\nWe now consider the malaria data from Kenya (Section 1.4.3) where the main outcome is the result from a rapid diagnostic test (RDT) for malaria from individuals within households. In this case, because the outcome only takes two values, 1 for a positive RDT test result and 0 otherwise, the direct application of the empirical logit from Equation 3.1 would not help us to generate informative scatter plots. Throughout the book, we will consider the data from the community survey only, hence we work with a subset of the data which we shall name malkenya_comm\n\nmalkenya_comm &lt;- malkenya[malkenya$Survey==\"community\", ]\n\nTo show how this issue can be overcome, let us consider the variables age and gender. To generate a plot that can help us understand between the relationship with malaria prevalence and the two risk factors, we proceed as follows.\n\n# Grouping of ages into classes defined through \"breaks\"\nmalkenya_comm$Age_class &lt;- cut(malkenya_comm$Age, \n                            breaks = c(0, 5, 10, 15, 30, 40, 50, 100),\n                            include.lowest = TRUE)\n\nUsing the cut function, we first split age (in years) into classes through the argument breaks. The classification of age into \\([0,5]\\), \\((5, 10]\\) and \\((10, 15]\\) is common in many malaria epidemiology studies, as children are one of the groups at highest risk malaria. The choice of the other classes of age reflects instead the need to balance the number of observations falling in each of the classes.\n\n# Computation of the empirical logit by age groups and gender\nage_class_data &lt;- aggregate(RDT ~ Age_class + Gender, \n                                    data = malkenya_comm, \n                                    FUN = function(y) \n                                    log((sum(y)+0.5)/(length(y)-sum(y)+0.5)))\n\nWe then compute the empirical logit, using the total number of cases within age group and by gender. For a given age group and gender, which we denote as \\(\\mathcal{C}\\), the empirical logit in Equation 3.1, now takes the form \\[\nl_{\\mathcal{C}} = \\log\\left\\{\\frac{\\sum_{i \\in \\mathcal{C}} y_{i} + 0.5}{|\\mathcal{C}|- \\sum_{i \\in \\mathcal{C}} y_{i} + 0.5} \\right\\}\n\\tag{3.4}\\] where \\(y_i\\) are the individual binary outcomes and \\(i\\in \\mathcal{C}\\) is used to indicate that the sum is carried out over all the individuals who belong the class \\(\\mathcal{C}\\), identified by a specific age group and gender. Finally, \\(|\\mathcal{C}|\\) is the number of individuals who fall within \\(\\mathcal{C}\\). In the code above, the empirical logit in Equation 3.4 is computed using the aggregate function. An inspection of the object age_class_data, a data frame, shows that the empirical is found in the column named RDT.\n\n# Computation of the average age within each age group \nage_class_data$age_mean_point &lt;- aggregate(Age ~ Age_class + Gender, \n                                 data = malkenya_comm, \n                                 FUN = mean)$Age\n\n\n# Number of individuals within each age group, by gender\nage_class_data$n_obs &lt;-  aggregate(Age ~ Age_class + Gender, \n                         data = malkenya_comm, \n                         FUN = length)$Age\n\nIn order to generate the scatter-plot, we compute the average age within each age group by gender, and use these as our values for the x-axis. Note that since we only need to obtain the average age from this output, we use $Age to extract this only and allocate to the column age_mean_point. Finally, we also compute the number of observations within each of classes and place this in n_obs.\n\nggplot(age_class_data, aes(x = age_mean_point, y = RDT, \n                           size = n_obs, \n                           colour = Gender)) + \n  geom_point() + \n  labs(x=\"Age (years)\",y=\"Empirical logit\")  \n\n\n\n\nFigure 3.4: Plot of the empirical logit against age, for males and females. The size of each solid point is rendered proportional to the number of individuals within age group, as indicated in the legend.\n\n\n\n\nThe resulting plot in Figure 3.4 shows the empirical logit against age by gender, with the size of each of the points proportional to the number of observations falling within each class. The observed patterns are explained by the fact that young children, especially those under the age of five, are particularly vulnerable to severe malaria infections. This is primarily due to their immature immune systems and lack of acquired immunity. As individuals grow older, they generally develop partial immunity to malaria through repeated exposure to the disease. This acquired immunity can provide some level of protection against severe malaria. At the same time, gender roles and activities can influence exposure to malaria-carrying mosquitoes. For example, men may spend more time outdoors for work or other activities, increasing their exposure to mosquito bites and thus their risk of infection. In addition, there are also biological factors to consider. Hormonal and genetic differences between males and females may also contribute to variations in immune responses to malaria infection. The interaction between age and gender is complex and may vary depending on the specific context and population being studied. A 2020 report from the Bill & Melinda Gates foundation provides a detailed overview of this and other aspects related to gender and malaria (Katz and Bill & Melinda Gates Foundation 2020).\nTo account for age in a model for malaria prevalence, several approaches are possible, some of which have been developed using biological models (Smith et al. 2007). To model the patterns observed in Figure 3.4, we can follow the same approach used in the previous section to model the relationship between elevation and river-blindness prevalence. First, let us consider age without the effect of gender. Let \\(p_{j}(x_i)\\) denote the probability of a positive RDT for the \\(j\\)-th individual living in a household at location \\(x_i\\). Assuming that malaria risk reaches its peak at 15 years of age, we can capture the non-linear relationship using a linear spline with two knots, one at 15 years and a second one at 40 years. This is expressed as \\[\n\\begin{aligned}\n\\log\\left\\{\\frac{p_{j}(x_i)}{1-p_j(x_i)}\\right\\} = \\beta_{0} + \\beta_{1}a_{ij}+\\beta_{2} \\times\\max\\{a_{ij}-15, 0\\} + \\beta_{3}\\max\\{a_{ij}-40, 0\\}\n\\end{aligned}\n\\tag{3.5}\\] where \\(a_{ij}\\) is the age, in years, for the \\(j\\)-th individual at household \\(i\\). Based on this model the effect of age on RDT prevalence is \\(\\beta_{1}\\), for \\(a_{ij} &lt; 15\\), \\(\\beta_{1}+\\beta_{2}\\), for \\(15 &lt; a_{ij} &lt; 40\\), and \\(\\beta_{1}+\\beta_{2}+\\beta_{3}\\) for \\(a_{ij} &gt; 40\\).\nFigure 3.4 indicates that age may interact with gender, meaning that the effect of gender on RDT prevalence changes across age, with larger differences observed between males and females for ages above 20 years. To assess such differences using a standard Binomial regression model, the linear predictor for RDT prevalence can be formulated as \\[\n\\begin{aligned}\n\\log\\left\\{\\frac{p_{j}(x_i)}{1-p_j(x_i)}\\right\\} = \\beta_{0} + (\\beta_{1} + \\beta_{1}^*g_{ij})\\times a_{ij}+(\\beta_{2} + \\beta_{2}^*g_{ij})\\times\\max\\{a_{ij}-15, 0\\} + \\\\\n(\\beta_{3} + \\beta_{3}^*g_{ij}) \\times \\max\\{a_{ij}-40, 0\\}\n\\end{aligned}\n\\tag{3.6}\\] where \\(g_{ij}\\) is the indicator for gender, with 1 corresponding to male and 0 to female. The coefficients \\(\\beta_{1}^*\\), \\(\\beta_{2}^*\\) and \\(\\beta_{3}^*\\) thus quantify the differences in risk between the two genders for ages below 15 years, betwee 15 and 40 years, and above 40 years, respectively. If all of those coefficients were 0, the model in Equation 3.5 would be recovered.\n\nglm_age_gender_interaction &lt;- glm(RDT ~ Age + Gender:Age + \n                                  pmax(Age-15, 0) + Gender:pmax(Age-15, 0) + \n                                  pmax(Age-40, 0) + Gender:pmax(Age-40, 0),\n                              data = malkenya_comm, family = binomial)\n\nsummary(glm_age_gender_interaction)\n## \n## Call:\n## glm(formula = RDT ~ Age + Gender:Age + pmax(Age - 15, 0) + Gender:pmax(Age - \n##     15, 0) + pmax(Age - 40, 0) + Gender:pmax(Age - 40, 0), family = binomial, \n##     data = malkenya_comm)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -0.7681  -0.7051  -0.4940  -0.2734   2.7294  \n## \n## Coefficients:\n##                              Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)                  -1.05835    0.10245 -10.331  &lt; 2e-16 ***\n## Age                          -0.03384    0.01310  -2.584  0.00978 ** \n## pmax(Age - 15, 0)            -0.03975    0.02356  -1.687  0.09162 .  \n## pmax(Age - 40, 0)             0.09170    0.02482   3.695  0.00022 ***\n## Age:GenderMale                0.01428    0.01221   1.170  0.24202    \n## GenderMale:pmax(Age - 15, 0) -0.03625    0.03145  -1.153  0.24908    \n## GenderMale:pmax(Age - 40, 0)  0.02451    0.04320   0.567  0.57052    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 2875.8  on 3351  degrees of freedom\n## Residual deviance: 2673.8  on 3345  degrees of freedom\n## AIC: 2687.8\n## \n## Number of Fisher Scoring iterations: 5\n\nThe code above shows how to fit the model specified in Equation 3.6. The terms Age, pmax(Age-15, 0) and pmax(Age-40, 0) respectively correspond to \\(\\beta_{1}\\), \\(\\beta_{2}\\) and \\(\\beta_{3}\\), whilst the Gender:Age, Gender:pmax(Age-15, 0) and Gender:pmax(Age-40, 0) to \\(\\beta_{1}^*\\), \\(\\beta_{2}^*\\) and \\(\\beta_{3}^*\\), respectively. In the summary of the fitted model, we observe that the interaction coefficients are non-statistically significant. However, removing the interaction based on the fact that each of the coefficients have each p-values larger than the conventional level of 5% would be wrong. Instead we should carry out the likelihood ratio test, as shown below.\n\nglm_age_gender_no_interaction &lt;- glm(RDT ~ Age +  pmax(Age-15, 0) + pmax(Age-40, 0),\n                              data = malkenya_comm, family = binomial)\n\nanova(glm_age_gender_no_interaction, glm_age_gender_interaction, test = \"Chisq\")\n## Analysis of Deviance Table\n## \n## Model 1: RDT ~ Age + pmax(Age - 15, 0) + pmax(Age - 40, 0)\n## Model 2: RDT ~ Age + Gender:Age + pmax(Age - 15, 0) + Gender:pmax(Age - \n##     15, 0) + pmax(Age - 40, 0) + Gender:pmax(Age - 40, 0)\n##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n## 1      3348     2675.6                     \n## 2      3345     2673.8  3   1.8051   0.6138\n\nTo carry out the likelihood ratio test to assess the null hypothesis that \\(\\beta_{1}^*=\\beta_{2}^*=\\beta_{3}^*=0\\), we first fit the simplified nested model under this null hypothesis. The likelihood ratio test can then be carried out using the anova command as shown. The p-value indicates that the we do not find evidence against the null hypothesis, hence in our analysis of the data we might favour the simplified model that does not assumes an interaction between the two genders.\nThe approach just illustrated, can also be applied to explore the association with other continuous variables that are a property of the household and not of the individual. Let us, for example, consider the variable elevation from the malkenya data-set.\n\nmalkenya_comm$elevation_class &lt;- cut(malkenya_comm$elevation,\n                            breaks = quantile(malkenya_comm$elevation, seq(0, 1, by = 0.1)),\n                            include.lowest = TRUE)\n\nFollowing the same approach used for age, we first split elevation into classes. To define these, we use the deciles of the empirical distribution of elevation which we calculate using the quantile function above. In this way we also ensure that the number of observations falling within each class of elevation is approximately the same.\n\n# Computation of the empirical logit by classes of elevation\nelev_class_data &lt;- aggregate(RDT ~ elevation_class, \n                                    data = malkenya_comm, \n                                    FUN = function(y) \n                                    log((sum(y)+0.5)/(length(y)-sum(y)+0.5)))\n\n\n# Computation of the average elevation within each class of elevation\nelev_class_data$elevation_mean &lt;- aggregate(elevation ~ elevation_class, \n                                    data = malkenya_comm, \n                                    FUN = mean)$elevation\n\nWe then compute the empirical logit and the average elevation for each class of elevation. The empirical logit is computed as already defined in Equation 3.4, where now the definition of \\(\\mathcal{C}\\) is given by a specific decile used to split the distribution of elevation.\n\nggplot(elev_class_data, aes(x = elevation_mean, y = RDT), \n                           size = n_obs) + \n  geom_point() + \n  labs(x=\"Elevation (meters)\",y=\"Empirical logit\")  \n\n\n\n\nFigure 3.5: Plot of the empirical logit against elevation measured in meters.\n\n\n\n\nThe resulting plot in Figure 3.5 shows an approximately linear relationship with decreasing values of the empirical logit for increasing elevation. This is expected because the cooler environment at higher altitudes is less favourable to the development of the overall mosquito life cycle.\nAn alternative approach to generate a scatter plot for assessing the association between elevation and the empirical logit would be to aggregate the data at household level, rather than using classes of elevation. However, this approach does not work as the one illustrated above when only one individual is sampled for each location. In the case of the malkenya data, the great majority of the locations only include one individual making this second approach less useful than the one illustrated.\nOther more sophisticated approaches for the exploration of the associations between covariates and binary outcomes are available. For example, the use of the empirical logit could be avoided by using non-parametric regression methods for Binomial outcomes (Bowman 1997), also implemented in sm package in R. Our view is that a careful exploratory analysis based on simpler methods, as those illustrated above, can be equally effective to inform the module formulation.\n\n\n\n3.1.2 Exploring overdispersion in count data\nOne of the main advantages in the use of covariates is the ability to attribute part of the variation of the outcome to a set of measured variables and, hence, reduce the uncertainty of our inferences. However, it almost always the case that the finite number of covariates at our disposal is not enough to fully explain the variation in the outcome. In other words, the existence of unmeasured covariates that are related to the modelled outcome give rise to the so called residual variation. In a standard linear regression model the extent to which we are able to account for important covariates is directly linked to the size of the variance of the residuals. In the case of count data, instead, this link is less well defined and one of the main consequences of the omission of covariates, which we address in this chapter, is overdispersion.\nOverdispersion occurs when the variability of the data is larger than that implied by the generalized linear model (GLM) fitted to them. For example, if we consider the Binomial distribution, the presence of overdispersion implies that \\(V(Y_i) &gt; n_i \\mu_{i}(1-\\mu_i)\\), where we recall that \\(n_i\\) is the Binomial denominator and \\(mu_i\\) is the probability of “success” for each of the \\(n_i\\) Bernoulli trials; for a Poisson distribution with \\(E(Y_i) = \\mu_i\\), instead, overdispersion implies that \\(V(Y_i) &gt; \\mu_{i}\\).\nAssessment of the overdispersion for count data can be carried out in different ways depending on the goal of the statistical analysis. Since the focus of this book is to illustrate how to formulate and apply geostatistical models, the most natural approach to assess overdispersion is through the use of generalized linear mixed models (GLMMs). The class of GLMMs that we consider in this and the next section are obtained by replacing the spatial Gaussian process \\(S(x_i)\\) in introduced in Equation 1.4 with a set of mutually independent random effects, which we denote as \\(Z_i\\), and thus write \\[\ng(\\mu_i) = d(x_i)^\\top \\beta + Z_i.\n\\tag{3.7}\\] The model above accounts for the overdispersion in the data through \\(Z_i\\) whose variance can be interpreted as an indicator of the amount of overdispersion. To show this, we carry out a small simulation as follows. For simplicity, we consider the Binomial mixed model with an intercept only, hence \\[\n\\log\\left\\{\\frac{\\mu_i}{1-\\mu_i}\\right\\} = \\beta_0 + Z_i\n\\tag{3.8}\\] and assume that the \\(Z_i\\) follow a set of mutually independent Gaussian variables with mean 0 and variance \\(\\tau^2\\). In our simulation we vary \\(\\beta_0\\) over the set \\(\\{-3, -2, -1, 0, 1, 2, 3\\}\\) and set \\(\\tau^2=0.1\\) and the binomial denominators to \\(n_i = 100\\). For a given value of \\(\\beta_0\\), we then proceed through the following iterative steps.\n\nSimulate 10,000 values for \\(Z_i\\) from a Gaussian distribution with mean 0 and variance \\(\\tau^2\\).\nCompute the probabilities \\(\\mu_i\\) based on Equation 3.8.\nSimulate 10,000 values from a Binomial model with probability of success \\(\\mu_i\\) and denominator \\(n_i\\).\nCompute the empirical variance of the counts \\(y_i\\) simulated in the previous step.\nChange the value of \\(\\beta_0\\) and repeat the previous steps, for all the values of \\(\\beta_0\\).\n\nThe code below shows the implementation of the above steps in R.\n\n# Number of simulations\nn_sim &lt;- 10000\n\n# Variance of the Z_i\ntau2 &lt;- 0.1\n\n# Binomial denominator \nbin_denom &lt;- 100\n\n# Intercept values\nbeta0 &lt;- c(-3, -2, -1, 0, 1, 2, 3)\n\n# Vector where we store the computed variance from\n# the simulated counts from the Binomial mixed model\nvar_data &lt;- rep(NA, length(beta0))\n\n\nfor(j in 1:length(beta0)) {\n  # Simulation of the random effects Z_i\n  Z_i_sim &lt;- rnorm(n_sim, sd = sqrt(tau2))\n\n  # Linear predictor of the Binomial mixed model\n  lp &lt;- beta0[j]  + Z_i_sim\n  \n  # Probabilities of the Binomial distribution conditional on Z_i\n  prob_sim &lt;- exp(lp)/(1+exp(lp))\n  \n  # Simulation of the counts from the Binomial mixed model\n  y_i_sim &lt;- rbinom(n_sim, size = bin_denom, prob = prob_sim)\n  \n  # Empirical variance from the simulated counts\n  var_data[j] &lt;- var(y_i_sim)\n}\n\n# Probabilities from the standard Binomial model (Z_i = 0)\nprobs_binomial &lt;- exp(beta0)/(1+exp(beta0))\n\n# Variance from the standard Binomial model\nvar_bimomial &lt;- bin_denom*probs_binomial*(1-probs_binomial)\n\n\nmatplot(beta0, cbind(var_data, var_bimomial), type = \"b\", pch = 20,\n        lty = \"solid\", ylab = \"Variance\", xlab = expression(beta[0]))\nlegend(-3, 80, c(\"Binomial mixed model\", \"Standard Binomial model\"),\n       col=1:2, lty = \"solid\", cex = 0.75)\n\n\n\n\nFigure 3.6: Plot of the variances of the standard Binomial model and the Binomial mixed model (see Equation 3.8) against \\(\\beta_0\\)\n\n\n\n\nFigure 3.6 shows the results of the simulation. In this figure, the red line corresponds to the variance of a standard Binomial model, obtained by setting \\(Z_i=0\\) and computed as \\(n_i \\mu_i (1-\\mu_i)\\) with \\(\\mu_i = \\exp\\{\\beta_0\\}/(1+\\exp\\{\\beta_0\\})\\). As expected, this plot shows that the variance of the simulated counts from the mixed model in Equation 3.8 exhibit a larger variance than would be expected under the standard Binomial model. It also indicates that the chosen value for the variance of \\(Z_i\\) of \\(\\tau^2 = 0.1\\) corresponds to a significant amount of dispersion. One way to relate \\(\\tau^2\\) to the amount of overdispersion is by considering that, following from the properties of a univariate Gaussian distribution, a priori the \\(Z_i\\) will take values between \\(-1.96 \\sqrt{\\tau^2}\\) and \\(+1.96 \\sqrt{\\tau^2}\\) with approximately 95\\(\\%\\) probability. That implies that \\(\\exp\\{Z_i\\}\\), which expresses the effect of the random effects on the odds ratios, will be with 95\\(\\%\\) probability between \\(\\exp\\{-1.96 \\sqrt{\\tau^2}\\}\\) and \\(\\exp\\{+1.96 \\sqrt{\\tau^2}\\}\\). By replacing \\(\\tau^2\\) with the chosen values for the simulation, those two becomes about 0.54 and 1.86, meaning that with the \\(Z_i\\) with \\(95\\%\\) probability will have a multiplicative effect on the odds ratios between \\(0.54\\) and \\(1.86\\).\nWe encourage you to do Exercise 1 and Exercise 2 at the end of this chapter, to further explore how generalized linear mixed models can be used as a tool to account for overdispersion.\n\n3.1.2.1 Maximum likelihood estimation of generalized linear mixed models\nWe now illustrate how to fit a generalize linear mixed, using the anopheles data-set as an example. We consider two models: an intercept-only model and one that uses elevation as a covariate. Let \\(\\mu(x_i)\\) be the number of mosquitoes captured at a location \\(x_i\\); then the linear predictor with elevation as a covariate takes the form \\[\n\\log\\{\\mu_i\\} = \\beta_{0} + \\beta_{1} d(x_i) + Z_i\n\\tag{3.9}\\] where \\(d(x_i)\\) indicates the elevation in meters at location \\(x_i\\) and the \\(Z_i\\) are independent and identically distributed Gaussian variables with mean 0 and variance \\(\\tau^2\\). The model with an intercept only is simply obtained by setting \\(\\beta_1 = 0\\).\nWe carry out the estimation in R using the glmer function from the lme4 package (see Bates et al. (2015) for a detailed tutorial). The glmer function implements the maximum likelihood estimation for generalized linear mixed models. The code below shows how the glmer is used to carry out this step for the model in Equation 3.9 and the one withuot covariates.\n\n# Create the ID of the location\nanopheles$ID_loc &lt;- 1:nrow(anopheles)\n\n# Poisson mixed model with elevation\nfit_glmer_elev &lt;- glmer(An.gambiae ~ scale(elevation) + (1|ID_loc), family = poisson, \n                        data = anopheles, nAGQ = 25)\n\n# Poisson mixed model with intercept only\nfit_glmer_int &lt;- glmer(An.gambiae ~ (1|ID_loc), family = poisson, \n                        data = anopheles, nAGQ = 25)\n\nTo fit the model with glmer, we first must create a variable in our data-set that allows us to identify the location associated with each count. In this case, since every row corresponds to a different location, we simply use the row number to identify the locations and save this in the ID_loc variable. The random effects \\(Z_i\\) are then included in the model by adding (1 | ID_loc) in the formula of the glmer function.\nWhen introducing the variable elevation, we standardize the variable so that its mean is 0 and its variance is 1. This is done to aid the convergence of the algorithm used to fit the model and it is generally considered good practice, especially when many variables with different scales are used as covariates. However, we emphasize that standardizing a variable does not affect the fit of the model to the data. This is because the model with the standardized variable is a reparametrization of the model with the unstandardized variable. In other words, a model that uses standardized covariates only attaches a different interpretation to its regression coefficients while maintaining the same goodness of fit of the model with that uses the covariates on their original scale.\nThe argument nAGQ is used to define the precision of the approximation of the maximum likelihood estimation algorithm. By default nAGQ = 1, which corresponds to the Laplace approximation. Values for nAGQ larger than 1 are used to define the number of points of the adaptive Gaussian-Hermite quadrature. The general principle is that the larger nAGQ the better, but at the expense of an increased computing time. Based on the guidelines and help pages of the lme4 package, it is stated that a reasonable value for nAGQ is 25. For more technical details on this aspect, we refer the reader to Bates et al. (2015).\nWe can now look at the summary of the fitted models to the mosquitoes data-set.\n\n### Summary of the model with elevation\nsummary(fit_glmer_elev)\n## Generalized linear mixed model fit by maximum likelihood (Adaptive\n##   Gauss-Hermite Quadrature, nAGQ = 25) [glmerMod]\n##  Family: poisson  ( log )\n## Formula: An.gambiae ~ scale(elevation) + (1 | ID_loc)\n##    Data: anopheles\n## \n##      AIC      BIC   logLik deviance df.resid \n##    291.8    300.1   -142.9    285.8      113 \n## \n## Scaled residuals: \n##      Min       1Q   Median       3Q      Max \n## -0.89574 -0.42469 -0.09483  0.29445  0.53352 \n## \n## Random effects:\n##  Groups Name        Variance Std.Dev.\n##  ID_loc (Intercept) 0.7146   0.8453  \n## Number of obs: 116, groups:  ID_loc, 116\n## \n## Fixed effects:\n##                  Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)       1.53042    0.09365  16.342   &lt;2e-16 ***\n## scale(elevation) -0.19794    0.08950  -2.212    0.027 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## scale(lvtn) 0.036\n\n### Summary of the model with the intercept only\nsummary(fit_glmer_int)\n## Generalized linear mixed model fit by maximum likelihood (Adaptive\n##   Gauss-Hermite Quadrature, nAGQ = 25) [glmerMod]\n##  Family: poisson  ( log )\n## Formula: An.gambiae ~ (1 | ID_loc)\n##    Data: anopheles\n## \n##      AIC      BIC   logLik deviance df.resid \n##    294.6    300.1   -145.3    290.6      114 \n## \n## Scaled residuals: \n##      Min       1Q   Median       3Q      Max \n## -0.73816 -0.42718 -0.06941  0.26564  0.45022 \n## \n## Random effects:\n##  Groups Name        Variance Std.Dev.\n##  ID_loc (Intercept) 0.761    0.8724  \n## Number of obs: 116, groups:  ID_loc, 116\n## \n## Fixed effects:\n##             Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)  1.52849    0.09584   15.95   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nFrom the summary of the model that uses elevation, we observe the that the estimated regression coefficient \\(\\beta_{1}\\) is statistically significant different from 0. The interpretation of the estimated regression coefficient is the following: for an increase of about 100 meters in elevation, all other things being equal, the average number of mosquitoes decreases by about \\(100\\% \\times [1-\\exp\\{-0.19794\\}] \\approx 18\\%\\). Note that when using a standardized variable, a unit increase for this corresponds to an increase in the original unstandardized variable equal to its standard deviation, which for the elevation variable is about 100 meters.\nFrom the summaries of the two models, under Random effects:, we obtain the estimates associates with the random effects introduced in the model. In this case, since we only have introduced \\(Z_i\\), this part of summary provides the maximum likelihood estimate for \\(\\tau^2\\), the variance of \\(Z_i\\), which found on the line where ID_loc is printed. We then observe that the estimates for \\(\\tau^2\\) for the intercept-only model is 0.761, whilst for the model with elevation this is 0.7146. Note that the figures reported under Std.Dev. are simply the square root of the value reported under Variance. As expected, the introduction of elevation contributes to the explanation of the residual variation captured by \\(Z_i\\), though by a very small amount. The estimated values of \\(\\tau^2\\) thus suggest that there is extra-Binomial variation in the data that is not account for by elevation.\nIn the next section, we will illustrate how to assess the presence of residual correlation for continuous measurements and overdispersed count data.\n\n\n\n3.1.3 Exploring residual spatial correlation\nIn its most basic form, the concept of spatial correlation can be succinctly encapsulated by Tobler (1970) first law of geography, which posits that “everything is interconnected, but objects in close proximity exhibit stronger relationships than those situated farther apart.” After we have identified the key variables to introduce as covariates in the model (Section 3.1.1) and, in the case of count data, assessed the presence of overdispersion (Section 3.1.2), our final exploratory step consists of assessing whether the residuals of the non spatial model show evidence of spatial correlation. Hence, in geostatistical modelling, the interest is not in the spatial correlation of the data, but rather on understanding whether the variation in the outcome unexplained by the covariates exhibits spatial correlation. We call this residual spatial correlation, to emphasize that spatial correlation is a concept relative to the covariates that we have introduced in the model.\nIn the context of geostatistical analysis, the tool that is generally used to assess the residual spatial correlation is the the so called empirical variogram. Before looking at the mathematical definition of the empirical variogram, let us consider a generalized linear mixed model as expressed in Equation 3.7. Our goal is then to question the assumption of independently distributed random effects \\(Z_i\\) by asking whether the \\(Z_i\\) show evidence of spatial correlation. Let \\(Z_i\\) and \\(Z_j\\) be two random effects that are associate with two different locations \\(x_i\\) and \\(x_j\\), respectively, and let us take the squared difference between the two \\[\nV_{ij} = (Z_i - Z_j)^2.\n\\tag{3.10}\\] How does the spatial correlation affect the value of \\(V_{ij}\\)? To answer this question, we can refer to the aforementioned Tobler’s law of geography. When \\(x_i\\) and \\(x_j\\) will be closer to each other, then \\(Z_i\\) and \\(Z_j\\) will also tend to be more similar to each other, thus making \\(V_{ij}\\) smaller, on average. On the contrary, when \\(x_i\\) and \\(x_j\\) will be further apart, then \\(V_{ij}\\) will become larger, on average. We can then construct the empirical variogram by considering all possible pairs of locations \\(x_i\\) and \\(x_j\\), for which we then compute \\(V_{ij}\\) and plot this against the distance between \\(x_i\\) and \\(x_j\\), which we denote as \\(u_{ij}\\). If there is spatial correlation in the random effects \\(Z_i\\), then this will manifest as an average increase in the \\(V_{ij}\\) as \\(u_{ij}\\) increases. However, there are still two issues that we have to address before we can generate and plot the empirical variogram.\nThe first issue is that we do not observe \\(Z_i\\) as, by definition, this is a latent variable. Hence, we require an estimate for \\(Z_i\\) which we can then feed into \\(V_{ij}\\). To emphasize this point, from now on, we shall replace Equation 3.10 with \\[\n\\hat{V}_{ij} = (\\hat{Z}_{i} - \\hat{Z}_j)^2.\n\\tag{3.11}\\] Several options are available for estimating \\(Z_{i}\\). Our choice is to use the model of the predictive distribution of \\(Z_i\\), that is the distribution of \\(Z_{i}\\) conditioned to the data \\(y_i\\). This estimator for \\(Z_i\\) is also readily available from the output of the lmer and glmer functions of the lme4 package, as we will illustrate later in our example in this section.\nThe second issue is that if simply plot \\(\\hat{V}_{ij}\\) against the distances \\(u_{ij}\\) (also knwon as cloud variogram), due to the high noiseness in the \\(\\hat{V}_{ij}\\), it may be quite difficult to assess the presence of an increasing trend in the \\(\\hat{V}_{ij}\\) and thus detect spatial correlation. Hence, it is general practice to group the distances \\(u_{ij}\\) into classes, say \\(\\mathcal{U}\\), and then take average of all the \\(\\hat{V}_{ij}\\) that fall within \\(\\mathcal{U}\\).\nWe can now write the formal definition of the empirical variogram as \\[\n\\hat{V}(\\mathcal{U}) = \\frac{1}{2 |\\mathcal{U}|} \\sum_{(i, j): (u_i, u_j) \\in \\mathcal{U}} \\hat{V}_{ij}\n\\tag{3.12}\\] where \\(|\\mathcal{U}|\\) denotes the number of pairs of locations that fall within the distance class \\(\\mathcal{U}\\). The rationale behind dividing by 2 in \\(1/2 |\\mathcal{U}|\\) from the above equation, will be elucidated in Section 3.2, and there is no need for us to delve into this matter at this juncture. When creating the empirical variogram plot, we select the midpoint values of the distance classes \\(\\mathcal{U}\\) to represent the x-axis values.\nBefore we can evaluate residual spatial correlation, there remains one crucial concern: relying solely on a visual inspection of the empirical variogram is susceptible to human subjectivity. Furthermore, it is worth noting that even a seemingly upward trend observed in the empirical variogram might be merely a product of random fluctuations, rather than a reliable indication of actual residual spatial correlation. To address these concerns and enhance the objectivity of the use of the empirical variogram, one approach would involve comparing the observed empirical variogram pattern with those generated in the absence of spatial correlation. Following this principle, we then use a permutation test that allows us to generate empirical variograms under the assumption of absence of spatial correlation through the following iterative steps.\n\nPermute the order of the locations in the data-set while keeping everything else fixed.\nCompute the empirical variogram \\(\\hat{V}(\\mathcal{U})\\) for the permuted data-set.\nRepeat 1 and 2 a large number of times, say 10,000.\nUse the resulting 10,000 empirical varigorams to compute 95\\(\\%\\) confidence intervals, by taking the 0.025 and 0.975 quantiles of these for each distance class \\(\\hat{V}(\\mathcal{U})\\).\nIf the observed empirical variogram falls fully within the envelope generated in the previous point, we then conclude that the data do not exhibit residual spatial correlation. If, instead, the observed empirical variogram partly falls outside the envelope we conclude that the data do exhibit residual spatial correlation.\n\nWe now show an application of all the concepts introduced in this section to the Liberia data on river-blindness.\n\n3.1.3.1 Using the empirical variogram to assess spatial correlation for the Liberia data\nWe consider the Binomial mixed model that uses the log-transformed elevation as a covariate to model river blindness prevalence, hence \\[\n\\log\\left\\{\\frac{p(x_i)}{1-p(x_i)}\\right\\} = \\beta_{0} + \\beta_{1}\\log\\{e(x_i)\\} + Z_i\n\\tag{3.13}\\] where \\(e(x_i)\\) is the elevation in meters at location \\(x_i\\) and the \\(Z_i\\) are i.i.d. Gaussian variables with mean 0 and variance \\(\\tau^2\\). We first fit the model above using the glmer function.\n\n# Convert the data-set into an sf object\nliberia &lt;- st_as_sf(liberia, coords = c(\"lat\", \"long\"), crs = 4326)\n\n\n# Create the ID of the location\nliberia$ID_loc &lt;- 1:nrow(liberia)\n\n# Binomial mixed model with log-elevation\nfit_glmer_lib &lt;- glmer(cbind(npos, ntest) ~ log(elevation) + (1|ID_loc), family = binomial,\n                        data = liberia, nAGQ = 25)\n\nsummary(fit_glmer_lib)\n\nGeneralized linear mixed model fit by maximum likelihood (Adaptive\n  Gauss-Hermite Quadrature, nAGQ = 25) [glmerMod]\n Family: binomial  ( logit )\nFormula: cbind(npos, ntest) ~ log(elevation) + (1 | ID_loc)\n   Data: liberia\n\n     AIC      BIC   logLik deviance df.resid \n   127.9    135.4    -61.0    121.9       87 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.46033 -0.63341 -0.07633  0.61995  3.12732 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ID_loc (Intercept) 0.003097 0.05565 \nNumber of obs: 90, groups:  ID_loc, 90\n\nFixed effects:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -2.96292    0.21184 -13.987  &lt; 2e-16 ***\nlog(elevation)  0.26143    0.04071   6.422 1.35e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nlog(elevtn) -0.981\n\n\nFrom the output, we observe that the estimate for \\(\\tau^2\\) is about 0.003, indicating a moderate level of overdispersion in the data.\n\nliberia$Z_hat &lt;- ranef(fit_glmer_lib)$ID_loc[,1]\n\nThrouhg the function ranef when extract the estimates of the random effects \\(Z_i\\) and save these in the data set. We then use the function s_variogram from the RiskMap package to compute the empirical varigoram for the estimated \\(\\hat{Z}_i\\).\n\nliberia_variog &lt;- s_variogram(data = liberia,\n                              variable = \"Z_hat\",\n                              bins = c(15, 30, 40, 80, 120,\n                                       160, 200, 250, 300, 350),\n                              scale_to_km = TRUE,\n                              n_permutation = 10000)\n\nThrough the argument bins we can specify the the classes of distance, previously denoted by \\(\\mathcal{U}\\); check the help page of s_variogram to see how this is defined by default. The value passed to bins in the code above correspond to define the following classes of distance \\(\\mathcal{U}\\): \\([15, 30]\\), \\((30, 40]\\) and so forth, with the last class being \\([350, +\\infty)\\), i.e. all pairs of locations whose distances are above 350km. The argument n_permutation allows the user to specify the number of permutations that are performed the generate the envelope for absence of spatial correlation previously described.\n\ndist_summaries(data = liberia,\n               scale_to_km = TRUE)\n## $min\n## [1] 3.34536\n## \n## $max\n## [1] 533.0733\n## \n## $mean\n## [1] 206.7424\n## \n## $median\n## [1] 192.6496\n\nThe dist_summaries function within the RiskMap package can be used for gauging the extent of the area covered by your dataset, aiding in the selection of appropriate values to be passed to the bins argument. In the provided output above, we can observe that for the Liberia dataset, the minimum and maximum distances span approximately 3km and 533km, respectively. While there is not a one-size-fits-all recommendation for setting bins, two fundamental principles should inform your decision-making. Firstly, it is advisable to avoid choosing overly large distance intervals, as the uncertainty associated with the empirical variogram tends to increase with distance due to fewer available pairs of observations for estimation. Secondly, especially when spatial correlation is not strong, it is crucial to carefully explore the behavior of the variogram at smaller distances. Consequently, it is generally advisable to experiment with different bins configurations and observe how they impact the pattern of the empirical variogram.\n\nplot_s_variogram(liberia_variog,\n                 plot_envelope = TRUE)\n\n\n\n\nFigure 3.7: Plot of the empirical variogram (solid line) computed using the estimated random effects from the model in Equation 3.13. The blue shaded area is the 95% confidence level envelope generated using the permutation procedure described in Section 3.1.3.\n\n\n\n\nFinally, the plot_s_variogram function enables us to visualize the empirical variogram and, through the plot_envelope argument, include the envelope generated by the permutation procedure. As illustrated in Figure 3.7, we observe that the empirical variogram falls outside the envelope at relatively short distances, typically below 30km. However, for distances exceeding 30km, the behavior of the empirical variogram does not significantly differ from variograms generated under the assumption of spatial independence. In summary, we interpret the evidence presented in Figure 3.7 as indicative of residual spatial correlation within the data. Nevertheless, it is essential to exercise caution when attempting to ascertain the scale of the spatial correlation using the empirical variogram. As we will emphasize throughout this book, the empirical variogram’s sensitivity to the choice of bins values renders it an unreliable tool for drawing statistical inferences. In other words, we advocate employing the empirical variogram primarily to assess the presence of residual correlation."
  },
  {
    "objectID": "03_model-fitting.html#sec-linear-model",
    "href": "03_model-fitting.html#sec-linear-model",
    "title": "3  Model formulation and parameter estimation",
    "section": "3.2 Linear Gaussian model",
    "text": "3.2 Linear Gaussian model\nIn this section, we consider spatially referenced outcomes \\(Y_i\\) that are continuous. For simplicity, we consider the case of a single measurement \\(Y_i\\) at each location \\(x_i\\). Recalling the class of generalized linear models introduced in Section 1.5, the linear predictor takes the form \\[\n\\mu_{i} = d(x_i)^\\top \\beta + S(x_i).\n\\tag{3.14}\\] Hence, in this case, we interpret \\(\\beta\\) as the effect on \\(\\mu_i\\) for a unit increase in \\(d(x_i)\\)."
  },
  {
    "objectID": "03_model-fitting.html#generalized-linear-geostatistical-models",
    "href": "03_model-fitting.html#generalized-linear-geostatistical-models",
    "title": "3  Model formulation and parameter estimation",
    "section": "3.3 Generalized linear geostatistical models",
    "text": "3.3 Generalized linear geostatistical models"
  },
  {
    "objectID": "03_model-fitting.html#theory",
    "href": "03_model-fitting.html#theory",
    "title": "3  Model formulation and parameter estimation",
    "section": "3.4 Theory",
    "text": "3.4 Theory\n\n3.4.1 The likelihood function of a genearlized linear mixed model"
  },
  {
    "objectID": "03_model-fitting.html#exercises",
    "href": "03_model-fitting.html#exercises",
    "title": "3  Model formulation and parameter estimation",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises\n\nConsider the Binomial mixed model with linear predictor as defined in Equation 3.7. By editing the code for the simulation shown in Section 3.1.2, generate a graph as in Figure 3.6 under the two following scenarios: \\(i\\)) \\(\\tau^2 = 0.2\\) and \\(n_i=100\\); \\(ii\\)) \\(\\tau^2 = 0.1\\) and \\(n_i = 1\\). How does the variance of \\(Y_i\\) change under \\(i\\)) and \\(ii\\)) in comparison to Figure 3.6? How do you explain the differences?\nSimilarly to the previous exercise, consider a Poisson mixed model with linear predictor \\[\n\\log\\left\\{\\mu_i\\right\\} = \\beta_0 + Z_i,\n\\] where \\(Z_i\\) are a set of mutually independent Gaussian variables with mean 0 and variance \\(\\tau^2\\). Using the code shown in Section 3.1.2, carry out a simulation study to compute the variance of \\(Y_i\\) and generate a graph similar to Figure 3.6 to compare the variance of the Poisson mixed model with that of a standard Poisson model. Generate the graph for different values of \\(\\tau^2\\) and summarize your findings. NOTE: In this simulation the offset \\(n_i\\) can be set to 1.\nCreate an R function that computes the cloud variogram. As explained in Section 3.1.3, the cloud variogram is obtained by plotting \\(\\hat{V}_ij\\) (see Equation 3.11) against the distances \\(u_ij\\). The function should take as input a data-set with three columns: the variable for which the cloud variogram is to be computed; and two columns corresponding to the location of the data. Then, use this function to create the cloud variogram for the model for river-blindness in Equation 3.13. How does this compare to empirical variogram that takes the averages within predefined distance classes, as shown in Figure 3.7?\nFit a Binomial mixed model to the Liberia data-set on river-blindness without any covariates, i.e. \\[\n\\log\\left\\{\\frac{p(x_i)}{1-p(x_i)}\\right\\} = \\beta_0 + Z_i.\n\\] Making use of the R code presented in Section 3.1.3.1, use the function s_variogram to generate the empirical variogram for this model and compare this to the empirical variogram of Figure 3.7. What differences do you observe?\n\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBowman, A. W. 1997. Applied Smoothing Techniques for Data Analysis : The Kernel Approach with s-Plus Illustrations. Oxford Statistical Science Series ; 18. Oxford : New York: Clarendon Press ; Oxford University Press.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer Series in Statistics. New York, NY, USA: Springer New York Inc.\n\n\nKatz, Elizabeth, and Bill & Melinda Gates Foundation. 2020. “Gender and Malaria Evidence Reivew.” Bill & Melinda Gates Foundation. https://www.gatesgenderequalitytoolbox.org/wp-content/uploads/BMGF_Malaria-Review_FC.pdf.\n\n\nSmith, David L, Carlos A Guerra, Robert W Snow, and Simon I Hay. 2007. “Standardizing Estimates of the Plasmodium Falciparum Parasite Rate.” Malaria Journal 6 (1): 131–31.\n\n\nTobler, W. R. 1970. “A Computer Movie Simulating Urban Growth in the Detroit Region.” Economic Geography 46: 234–40.\n\n\nWeisberg, Sanford. 2014. Applied Linear Regression. Fourth. Hoboken NJ: Wiley. http://z.umn.edu/alr4ed."
  },
  {
    "objectID": "03_model-fitting.html#footnotes",
    "href": "03_model-fitting.html#footnotes",
    "title": "3  Model formulation and parameter estimation",
    "section": "",
    "text": "The letter \\(e\\) stands for the so called Euler’s number and represents the base of the natural logarithm. In the book, we write \\(\\log(\\cdot)\\) to mean the “natural logarithm of \\(\\cdot\\)”.↩︎"
  },
  {
    "objectID": "04_model-validation.html#how-to-simulate-geostatistical-data-from-a-fitted-model",
    "href": "04_model-validation.html#how-to-simulate-geostatistical-data-from-a-fitted-model",
    "title": "4  Model validation",
    "section": "4.1 How to simulate geostatistical data from a fitted model",
    "text": "4.1 How to simulate geostatistical data from a fitted model"
  },
  {
    "objectID": "04_model-validation.html#validating-the-calibration-of-the-model",
    "href": "04_model-validation.html#validating-the-calibration-of-the-model",
    "title": "4  Model validation",
    "section": "4.2 Validating the calibration of the model",
    "text": "4.2 Validating the calibration of the model"
  },
  {
    "objectID": "04_model-validation.html#validating-the-spatial-correlation-of-the-model",
    "href": "04_model-validation.html#validating-the-spatial-correlation-of-the-model",
    "title": "4  Model validation",
    "section": "4.3 Validating the spatial correlation of the model",
    "text": "4.3 Validating the spatial correlation of the model"
  },
  {
    "objectID": "05_geostatistical-prediction.html#pixel-level-predictive-targets",
    "href": "05_geostatistical-prediction.html#pixel-level-predictive-targets",
    "title": "5  Geostatistical prediction",
    "section": "5.1 Pixel-level predictive targets",
    "text": "5.1 Pixel-level predictive targets"
  },
  {
    "objectID": "05_geostatistical-prediction.html#area-level-predictive-targets",
    "href": "05_geostatistical-prediction.html#area-level-predictive-targets",
    "title": "5  Geostatistical prediction",
    "section": "5.2 Area-level predictive targets",
    "text": "5.2 Area-level predictive targets"
  },
  {
    "objectID": "05_geostatistical-prediction.html#comparing-the-predictive-performance-of-geostatistical-models",
    "href": "05_geostatistical-prediction.html#comparing-the-predictive-performance-of-geostatistical-models",
    "title": "5  Geostatistical prediction",
    "section": "5.3 Comparing the predictive performance of geostatistical models",
    "text": "5.3 Comparing the predictive performance of geostatistical models"
  },
  {
    "objectID": "06_case-studies.html#mapping-stunting-risk-in-ghan",
    "href": "06_case-studies.html#mapping-stunting-risk-in-ghan",
    "title": "6  Case studies",
    "section": "6.1 Mapping stunting risk in Ghan",
    "text": "6.1 Mapping stunting risk in Ghan"
  },
  {
    "objectID": "06_case-studies.html#mapping-river-blindness-in-malawi",
    "href": "06_case-studies.html#mapping-river-blindness-in-malawi",
    "title": "6  Case studies",
    "section": "6.2 Mapping river blindness in Malawi",
    "text": "6.2 Mapping river blindness in Malawi"
  },
  {
    "objectID": "06_case-studies.html#mapping-mosquitoes-abundance-in-cameroon",
    "href": "06_case-studies.html#mapping-mosquitoes-abundance-in-cameroon",
    "title": "6  Case studies",
    "section": "6.3 Mapping mosquitoes abundance in Cameroon",
    "text": "6.3 Mapping mosquitoes abundance in Cameroon"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.\n“Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical\nSoftware 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBowman, A. W. 1997. Applied Smoothing Techniques for Data Analysis :\nThe Kernel Approach with s-Plus Illustrations. Oxford Statistical\nScience Series ; 18. Oxford : New York: Clarendon Press ; Oxford\nUniversity Press.\n\n\nBreslow, N. E., and D. G. Clayton. 1993. “Approximate Inference in\nGeneralized Linear Mixed Models.” Journal of the American\nStatistical Association 88: 9–25.\n\n\nChilès, J-P, and P. Delfiner. 2016. Geostatistics (Second\nEdition). Hoboken: Wiley.\n\n\nCressie, N. A. C. 1991. Statistics for Spatial Data. New York:\nWiley.\n\n\nDiggle, P. J., J. A. Tawn, and R. A. Moyeed. 1998. “Model-Based\nGeostatistics.” Journal of the Royal Statistical Society:\nSeries C (Applied Statistics) 47 (3): 299–350. https://doi.org/10.1111/1467-9876.00113.\n\n\nDobson, A. J., and A. Barnett. 2008. An Introduction to Generalized\nLinear Models. Third. Chapman; Hall/CRC.\n\n\nFernández, J. A, A Rey, and A Carballeira. 2000. “An Extended\nStudy of Heavy Metal Deposition in Galicia (NW Spain) Based on Moss\nAnalysis.” Science of The Total Environment 254 (1):\n31–44. https://doi.org/10.1016/S0048-9697(00)00431-9.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The\nElements of Statistical Learning. Springer Series in Statistics.\nNew York, NY, USA: Springer New York Inc.\n\n\nKatz, Elizabeth, and Bill & Melinda Gates Foundation. 2020.\n“Gender and Malaria Evidence Reivew.” Bill & Melinda\nGates Foundation. https://www.gatesgenderequalitytoolbox.org/wp-content/uploads/BMGF_Malaria-Review_FC.pdf.\n\n\nKrige, D. G. 1951. “A Statistical Approach to Some Basic Mine\nValuation Problems on the Witwatersrand.” Journal of the\nChemical, Metallurgical and Mining Society of South Africa 52:\n119–39.\n\n\nMatern, B. 2013. Spatial Variation. Lecture Notes in\nStatistics. Springer New York. https://books.google.co.uk/books?id=HrbSBwAAQBAJ.\n\n\nMatheron, G. 1963. “Principles of Geostatistics.”\nEconomic Geology 58: 1246–66.\n\n\nNelder, J. A., and R. W. M. Wedderburn. 1972. “Generalized Linear\nModels.” Journal of the Royal Statistical Society A 135:\n370–84.\n\n\nPawitan, Yudi. 2001. In All Likelihood : Statistical Modelling and\nInference Using Likelihood. Oxford ; New York: Clarendon Press :\nOxford University Press.\n\n\nRipley, B. D. 1981. Spatial Statistics. New York: Wiley.\n\n\nRoss, Sheldon. 2013. First Course in Probability, a. 9th ed.\nHarlow: Pearson Education UK.\n\n\nSmith, David L, Carlos A Guerra, Robert W Snow, and Simon I Hay. 2007.\n“Standardizing Estimates of the Plasmodium Falciparum Parasite\nRate.” Malaria Journal 6 (1): 131–31.\n\n\nStevenson, Gillian H. AND Gitonga, Jennifer C. AND Stresman. 2013.\n“Reliability of School Surveys in Estimating Geographic Variation\nin Malaria Transmission in the Western Kenyan Highlands.”\nPLOS ONE 8 (10). https://doi.org/10.1371/journal.pone.0077641.\n\n\nTene Fossog, Billy, Diego Ayala, Pelayo Acevedo, Pierre Kengne, Ignacio\nNgomo Abeso Mebuy, Boris Makanga, Julie Magnus, et al. 2015.\n“Habitat Segregation and Ecological Character Displacement in\nCryptic African Malaria Mosquitoes.” Evolutionary\nApplications 8 (4): 326–45. https://doi.org/10.1111/eva.12242.\n\n\nTobler, W. R. 1970. “A Computer Movie Simulating Urban Growth in\nthe Detroit Region.” Economic Geography 46: 234–40.\n\n\nWatson, G. S. 1971. “Trend -Surface Analysis.”\nMathematical Geology 3: 215–26.\n\n\n———. 1972. “Trend Surface Analysis and Spatial\nCorrelation.” Geological Society of America Special\nPaper 146: 39–46.\n\n\nWeisberg, Sanford. 2014. Applied Linear Regression. Fourth.\nHoboken NJ: Wiley. http://z.umn.edu/alr4ed.\n\n\nZouré, Honorat GM, Mounkaila Noma, Afework H Tekle, Uche V Amazigo,\nPeter J Diggle, Emanuele Giorgi, and Jan HF Remme. 2014.\n“Geographic Distribution of Onchocerciasis in the 20 Participating\nCountries of the African Programme for Onchocerciasis Control: (2)\nPre-Control Endemicity Levels and Estimated Number Infected.”\nParasites & Vectors 7 (1): 326–26."
  },
  {
    "objectID": "01_intro.html#sec-geostat-models",
    "href": "01_intro.html#sec-geostat-models",
    "title": "1  Introduction",
    "section": "1.5 Geostatistical problems and geostatistical models",
    "text": "1.5 Geostatistical problems and geostatistical models\nWhat the examples of the previous section have in common is that, in each case, the goal of statistical analysis is to draw inferences on an unobserved spatially continuous surface using data collected from a finite set of locations. The lead concentration in Galicia, the prevalence for river-blindness in Liberia and the abundance of A. gambiae mosquitoes in Cameroon can all be represented as spatially continuous processes that originate from the combined effects of environmental factors. We denote this class of inferential problems as geostatistical problems for which a solution can be found through the development and application of suitable geostatistical models, which are the subject of this book.\nAs one can soon realize, geostatistical problems are not unique to global health but arise in many other fields of science, including economics, physics, biology, geology and others. It thus comes to no surprise that geostatistics was initially developed in the South African mining industry in the 1950s (Krige 1951). This was then further developed as a self-contained discipline by Georges Matheron and other researchers at Fontainebleau, in France (Matheron 1963; Chilès and Delfiner 2016). In Watson (1971) and Watson (1972) a first connection is drawn between geostatistics and the prediction of stochastic processes. However, it is only with Ripley (1981) and then Cressie (1991) that geostatistics is explicitly brought into a classical statistical framework for the analysis of spatially referenced data. Diggle, Tawn, and Moyeed (1998) coined the term model-based geostastics and introduced this as belonging to the general class of generalized linear mixed models (Breslow and Clayton 1993), while emphasizing the use of likelihood-based methods of inference. As in Diggle, Tawn, and Moyeed (1998), also in this book, we advocate the application of model-based geostistical models as a class of parametric statistical models on which inference can be carried out using either maximum likelihood estimation or Bayesian methods.\nMore precisely, our attention will be directed at the class of generalized linear geostatistical models, or GLGM. To formally specify this, we first define the random variables \\(S\\), a spatial stochastic process, and the random variable \\(Y= (Y_1, \\ldots, Y_n)\\) which correspond to the outcome observed at a set of locations \\(X = (x_1, \\ldots, x_n)\\). Let us use \\([A]\\) to denote “the distribution of the random variable \\(A\\)”. To formulate a GLGM, we should then specify the joint distribution of \\(S\\) and \\(Y\\), which we write as\n\\[\n[Y, S] = [S] [Y | S].\n\\tag{1.1}\\]\nOn the right-hand side of the equation above, we have factorized the joint distribution of \\(Y\\) and \\(S\\), as the product between the marginal distribution of \\(S\\) and the conditional distribution of \\(Y\\) given \\(S\\). Hence, the formulation of a GLGM can be break down into the tasks of formulating \\([S]\\) and \\([Y | S]\\).\nIn defining \\([S]\\), throughout the book, we shall assume that this is a zero-mean stationary and isotropic Gaussian process. In other words, these assumptions impose that the joint distribution of \\(S(X) = (S(x_1),\\ldots,S(x_n))\\), i.e. the process \\(S\\) at the sampled locations \\(x_1, \\ldots, x_n\\), is invariant with respect to rations and translations of the locations \\(X\\). In practical terms, the main implication of this is that, for any pair of locations \\(x_i\\) and \\(x_j\\) the correlation function \\(\\rho(\\cdot)\\) between \\(S(x_i)\\) and \\(S(x_j)\\) is purely a function of the Euclidean distance, \\(u_{ij}\\), between \\(x_i\\) and \\(x_j\\), i.e. \\[\n{\\rm cov}\\{S(x_i), S(x_j)\\} = \\sigma^2\\rho(u_{ij}),\n\\tag{1.2}\\]\nwhere \\(\\sigma^2\\) is the variance of \\(S(x)\\) for all \\(x\\). Below we provide more details on the type of covoriance functions that we consider in this book. Furthermore, the fact that we assume the process \\(S\\) to have mean zero is because this is process acts as a residual term in our modelling of \\(Y\\). This aspect will be reiterated several times in the following chapters, as it as important implications for the interpretation of the other components of a geostatistical model, as well understanding the results of the analysis.\nFinally, we model \\([Y | S]\\), i.e. the distribution of \\(Y\\) given \\(S\\), is modeled as a set of mutually independent distributions which belong the exponential family, as defined in classical generalized linear modelling framework (Nelder and Wedderburn 1972). It then follows that, we can write \\([Y | S]\\) as\n\\[\n[Y | S] = \\prod_{i=1}^n [Y_i | S(x_i)].\n\\tag{1.3}\\]\nThe final step then consists of specifying a distribution for \\([Y_i | S(x_i)]\\). Table 1.3 gives the range, mean and variance the three specifications for $[Y_i | S(x_i)]$$ which we will consider in this book. In Table 1.3, the canonical function, say \\(g(\\cdot)\\), denotes the natural transformation of the mean component \\(\\mu_i\\) that allows us to introduce both covariates and the spatial process \\(S(x_i)\\) into the model so as to explain the variation in \\(\\mu_i\\) as\n\\[\ng(\\mu_i) = d(x_i)^\\top \\beta + S(x_i).\n\\tag{1.4}\\]\nwhere \\(d(x_i)\\) is a vector of spatially referenced covariates with associated regression coefficients \\(\\beta\\). Finally, the quantity \\(m_i\\), which appears in the formulation of the Binomial and Poisson distributions, is an offset quantity and is used to account for the number of tests or the population size at a given location \\(x_i\\).\n\n\nTable 1.3: Type of outcomes \\(Y_{i}\\) considered in this book.\n\n\n\n\n\n\n\n\n\nDistribution\nRange of \\(Y_i\\)\nMean of \\([Y_i | S(x_i)]\\)\nVariance of \\([Y_i | S(x_i)]\\)\nCanonical link\n\n\n\n\nGaussian\n\\((-\\infty, +\\infty)\\)\n\\(\\mu_i\\)\n\\(\\tau^2\\)\n\\(g(\\mu_i) = \\mu_i\\)\n\n\nBinomial\n\\(1,\\dots,m_i\\)\n\\(m_i\\mu_i\\)\n\\(m_i\\mu_i(1-\\mu_i)\\)\n\\(g(\\mu_i) = \\log\\{ \\mu_i/(1-\\mu_i) \\}\\)\n\n\nPoisson\n\\(1,2,\\ldots,\\infty\\)\n\\(m_i\\mu_i\\)\n\\(m_i\\mu_i\\)\n\\(g(\\mu_i) = \\log\\{ \\mu_i \\}\\)\n\n\n\n\nBased on the formulation in (1.4), we can see that \\(S(x_i)\\) quantifies residual spatial effects on \\(\\mu_i\\) that have not been accounted for by the covariates \\(d(x_i)\\). In an ideal scenario, the covariates \\(d(x_i)\\) should explain all the spatial variation without the need for \\(S(x_i)\\). Although this unrealistic, in practice we may be able to most of the variation in \\(\\mu_i\\) through \\(d(x_i)\\) and, hence, reduce \\(S(x_i)\\) to a negligible component. In Chapter 2, we will show how a thorough exploratory analysis can help to understand whether we have come close to that ideal scenario or, if instead, we need the use of GLGM to model the data.\nThe model described in (1.4) can be seen as the most basic GLGM that can be used for a geostatistical analysis. As we will see in the analysis of some of the examples and, in Chapter 6, for the case studies, extensions of this model will be required to accommodate the intrinsic non-spatial random variation of the data which is not captured by the covariates.\nThe types of problems that statistical models are applied to can be distinguished into three main categories: prediction problems; explanatory problems; problems of hypothesis testing. Most of the times, geostatistical problems tend to fall under the first category, where the goal is make predictive inferences on the process \\(S(x)\\) at location \\(x\\), which is usually outside of the set of sampled locations. However, as will illustrate in the later chapters, geostatistical models play an important also in the other two types of problems. In particular, we will show that spatial correlation can have a substantial impact on the point estimates and standard errors for \\(\\beta\\). Hence, if the goal of the analysis is explain the relationship between a covariate \\(d(x)\\) with the mean component \\(\\mu\\).\n\n1.5.1 The Matern family of correlation functions\nThroughout the book, we shall consider the Matern (2013) family of correlation functions to model the spatial correlation of the Gaussian process \\(S(x)\\). This defined as \\[\n\\rho(u;\\phi,\\kappa) =\\{2^{\\kappa-1} \\Gamma(\\kappa)\\}^{-1} (u/\\phi)^\\kappa K_\\kappa(u/\\phi),\n\\tag{1.5}\\] where \\(\\phi&gt;0\\) and \\(\\kappa&gt;0\\) are parameters and \\(K_\\kappa(\\cdot)\\) is the modified Bessel function of the third kind of order \\(\\kappa\\). The parameters \\(\\phi\\) and \\(\\kappa\\) regulate how fast the spatial correlation decays to zero for increasing distance and the smoothness of the process, respectively. A special case of Matern family of correlation functions, which is obtained when \\(\\kappa=0.5\\), will be of particular relevance to the application considered in this book. This is the expeonential correlation function which we write as \\[\n\\rho(u;\\phi) = \\exp\\{-u/\\phi\\}.\n\\tag{1.6}\\]\nAnother special case, which we dot consider in this book but has often been used in machine learning applications, is the Gaussian correlation function obtain as a limiting case for \\(\\kappa \\to +\\infty\\) the possible smoothest process arising from the Matern family.\nTo better understand how \\(\\phi\\) and \\(\\kappa\\) affect the spatial correlation and the pattern of the spatial of the spatial surface, we now consider some examples.\n\n\n\n\n\nFigure 1.6: Examples of stationary and isotropic Matern correlation functions. Panel (a) shows three different correlations functions that have the same smothness parameter of \\(\\kappa=0.5\\), while varying the scale parameter \\(\\phi\\) over \\({0.05, 0.1, 0.2}\\). In panel (b) the scale of the spatial correlation \\(\\phi\\) is chosen so that each of the three functions reaches 0.05 at distance 0.3 (as also shown by the horizontal and vertical black dashed segments).\n\n\n\n\nFigure 1.6 shows six different Matern correlation functions. In panel (a), we have kept \\(\\kappa\\) fixed to 0.5 and varied \\(\\phi\\) over the values 0.05, 0.1 and 0.2. As expected, for larger values of \\(\\phi\\) the correlation function has a slower decay to zero. Panels (a) to (c), in Figure 1.7, show three realizations of a Gaussian process from each of these correlation functions. The mean of the Gaussian process was set to zero and variance to 1. We can observe that spatial correlations with larger scales are associated with longer spatial trends, whilst smaller scales exhibit a patchier pattern. This is because, as \\(\\phi\\) takes values that are closer to zero, the spatial surface will tend to show a less structured pattern and will revert towards its zero mean more rapidly.\nFinally, let us consider the correlation functions, shown in the panel (b) of Figure 1.6. Here, we have varied \\(\\kappa\\) over the values 0.5, 1.5 and 2.5, whilst \\(\\phi\\) has been fixed in order to force all three correlation functions to reach 0.05 for distance 0.3. In this way, we can better observe the effect of different values \\(\\kappa\\) on the spatial surface for process that have approximately the same range for the spatial correlation. In Figure 1.7, we observe three realizations from these correlation functions. We observe that the differences between the different surface are determined by the small spatial scale behaviour; \\(\\kappa = 0.5\\) correspond to a rougher and less regular spatial pattern, whilst \\(\\kappa=2.5\\) shows a smoothest surface of the three processes considered. These properties of the spatial surface are related to the so called differentiability of the the Guassian process, which determines its local behaviour. If you are interested in delving these theoretical aspects, we suggest reading Chapter 2 of (stein2005?).\n\n\n\n\n\nFigure 1.7: Simulated spatial surface using the three correltion functions shown in Figure 1.6. Panels (a), (b) and (c) correspond to the correlation functions from panel (a) in Figure 1.6 and in order these are: \\(\\phi = 0.05\\) and \\(\\kappa=0.5\\); (b) \\(\\phi=0.1\\) and \\(\\kappa=0.5\\); (c) \\(\\phi=0.2\\) and \\(\\kappa=0.5\\). Panels (c), (d) and (e) correspond to the correlation functions from panel (b) in Figure 1.6 and in order these are: \\(\\phi = 0.1\\) and \\(\\kappa=0.5\\); (b) \\(\\phi=0.063\\) and \\(\\kappa=1.5\\); (c) \\(\\phi=0.051\\) and \\(\\kappa=2.5\\).\n\n\n\n\nThe flexibility provided by the Matern correlation function in capturing different forms of spatial correlations has made one of, if not the most widely used correlation function in model-based geostatistics (Stein 1999). For this reason, in this book we will consider the Matern correlation function. We will consider estimation issues related to the Matern correlation in Chapter 3."
  },
  {
    "objectID": "01_intro.html#workflow-of-a-statistical-analysis-and-structure-of-the-book",
    "href": "01_intro.html#workflow-of-a-statistical-analysis-and-structure-of-the-book",
    "title": "1  Introduction",
    "section": "1.6 Workflow of a statistical analysis and structure of the book",
    "text": "1.6 Workflow of a statistical analysis and structure of the book\n\n\n\nFigure 1.8: Stages of a statistical analysis\n\n\nFigure 1.8 shows the different stages that will follow in carrying the geostatistical analysis of the examples introduced in Section 1.4. The exploratory analysis of the data is an essential first step that is used to understand the empirical associations between risk factors and the the health outcome of interest. In our case, this first stage is also used to justify the use of geostatistical models by questioning the underlying assumptions of standard generalized linear models. Based on the results obtained from the exploration of the data, we then formulate a suitable statistical model and estimate its parameters using likelihood based methods of inference. These also allows us to obtain uncertainty measures about the strength of associations of regression relationships and the other model parameters that define the shape of the spatial correlation in the data. Following the estimation of the model, we then proceed to validate its underlying assumptions using suitable diagnostics that assess whether the model can later be sufficiently trusted to represent the observed variation in the modelled outcome. At this stage, if the diagnostics checks yield results that indicate the incompatibility of the model with the data, we then back to the stage of model formulation and address the issues arisen from the validation stage. If instead, we do not find any evidence against the fitted model we can proceed to carry out sptatial prediction. At this stage, it is important to define suitable predictive targets that can help us to better answer the original research question and better assist the decision making process. The final step of visualization of uncertainty plays an important role in geostatistical analysis in order to convey the main findings of the study in an effective and easy-to-understand way for a wider audience which also consists of non-experts.\nIn the remainder of this book, each chapter focuses on a specific stage as shown in Figure 1.8. We treat visualization of uncertainty together with spatial prediction in Chapter 5.\nChapter 2 will provide an overview of how to handle saptial data in R, in particular raster and shape files. The skills learned in this chapter will be applied throughout the book, and will especially be useful in Chapter 5 and Chapter 6 for generating predictive maps of the modelled outcome.\nChapter 3 focuses on the model building process and estimation of geostatistical models. This chapter will show how to carry out initial exploratory analyses of the data to inform the formulation of suitable geostatistical models and how these can be fitted using maximum likelihood estimation methods.\nChapter 4 illustrated the use of methods that can be used to validate the assumptions and calibration of statistical models.\nChapter 5 shows how geostatistical models can be used to carry out spatial prediction of a health outcome of interest both on a spatially continuous and spatially aggregated scales.\nFinally, Chapter 6 presents the application of all the methods illustrated in the previous chapters to three additional data-sets. This chapter offers a summary of the content of book by putting together all the stages in the geostatistical analyses for each of the three case studies, and illustrates additional functionalities of the RiskMap R package not covered in the previous chapters.\n\n\n\n\nBreslow, N. E., and D. G. Clayton. 1993. “Approximate Inference in Generalized Linear Mixed Models.” Journal of the American Statistical Association 88: 9–25.\n\n\nChilès, J-P, and P. Delfiner. 2016. Geostatistics (Second Edition). Hoboken: Wiley.\n\n\nCressie, N. A. C. 1991. Statistics for Spatial Data. New York: Wiley.\n\n\nDiggle, P. J., J. A. Tawn, and R. A. Moyeed. 1998. “Model-Based Geostatistics.” Journal of the Royal Statistical Society: Series C (Applied Statistics) 47 (3): 299–350. https://doi.org/10.1111/1467-9876.00113.\n\n\nDobson, A. J., and A. Barnett. 2008. An Introduction to Generalized Linear Models. Third. Chapman; Hall/CRC.\n\n\nFernández, J. A, A Rey, and A Carballeira. 2000. “An Extended Study of Heavy Metal Deposition in Galicia (NW Spain) Based on Moss Analysis.” Science of The Total Environment 254 (1): 31–44. https://doi.org/10.1016/S0048-9697(00)00431-9.\n\n\nKrige, D. G. 1951. “A Statistical Approach to Some Basic Mine Valuation Problems on the Witwatersrand.” Journal of the Chemical, Metallurgical and Mining Society of South Africa 52: 119–39.\n\n\nMatern, B. 2013. Spatial Variation. Lecture Notes in Statistics. Springer New York. https://books.google.co.uk/books?id=HrbSBwAAQBAJ.\n\n\nMatheron, G. 1963. “Principles of Geostatistics.” Economic Geology 58: 1246–66.\n\n\nNelder, J. A., and R. W. M. Wedderburn. 1972. “Generalized Linear Models.” Journal of the Royal Statistical Society A 135: 370–84.\n\n\nPawitan, Yudi. 2001. In All Likelihood : Statistical Modelling and Inference Using Likelihood. Oxford ; New York: Clarendon Press : Oxford University Press.\n\n\nRipley, B. D. 1981. Spatial Statistics. New York: Wiley.\n\n\nRoss, Sheldon. 2013. First Course in Probability, a. 9th ed. Harlow: Pearson Education UK.\n\n\nStein, Michael L. 1999. Interpolation of Spatial Data Some Theory for Kriging. 1st ed. 1999. Springer Series in Statistics. New York, NY: Springer New York : Imprint: Springer.\n\n\nStevenson, Gillian H. AND Gitonga, Jennifer C. AND Stresman. 2013. “Reliability of School Surveys in Estimating Geographic Variation in Malaria Transmission in the Western Kenyan Highlands.” PLOS ONE 8 (10). https://doi.org/10.1371/journal.pone.0077641.\n\n\nTene Fossog, Billy, Diego Ayala, Pelayo Acevedo, Pierre Kengne, Ignacio Ngomo Abeso Mebuy, Boris Makanga, Julie Magnus, et al. 2015. “Habitat Segregation and Ecological Character Displacement in Cryptic African Malaria Mosquitoes.” Evolutionary Applications 8 (4): 326–45. https://doi.org/10.1111/eva.12242.\n\n\nWatson, G. S. 1971. “Trend -Surface Analysis.” Mathematical Geology 3: 215–26.\n\n\n———. 1972. “Trend Surface Analysis and Spatial Correlation.” Geological Society of America Special Paper 146: 39–46.\n\n\nZouré, Honorat GM, Mounkaila Noma, Afework H Tekle, Uche V Amazigo, Peter J Diggle, Emanuele Giorgi, and Jan HF Remme. 2014. “Geographic Distribution of Onchocerciasis in the 20 Participating Countries of the African Programme for Onchocerciasis Control: (2) Pre-Control Endemicity Levels and Estimated Number Infected.” Parasites & Vectors 7 (1): 326–26."
  }
]