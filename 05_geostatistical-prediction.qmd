---
filters:
  - line-highlight
execute: 
  freeze: auto
fig-width: 5
fig-asp: 0.75
---

# Geostatistical prediction {#sec-geo-prediction}

## List of the main functions used in the chapter {.unnumbered}

| Function           | R Package | Used for                                                                                                              |
|-------------------------|------------------|-----------------------------|
| `pred_over_grid`   | `RiskMap` | Predicting the different component of the linear predictor over a grid: the covariates effects and the random effects |
| `pred_target_grid` | `RiskMap` | Predictions of target defined at pixel-level                                                                          |
| `pred_target_shp`  | `RiskMap` | Predictions of targets defined at areal level                                                                         |
| `assess_pp`        | `RiskMap` | Assessing the predictive performance of geostatistical models                                                         |

## Introduction

Geostatistics was originally developed and applied as a predictive tool for improving mining operations and planning. In the seminal paper on model-based geostatistics (MBG) [@diggle1998], the authors begin by stating:

> \*"Conventional geostatistical methodology solves the problem of predicting the realized value of a linear functional of a Gaussian spatial stochastic process\* $S(x)$ based on observations $Y_i= S(x_i) + Z_i$ at sampling locations $x_i$, where the $Z_i$ are mutually independent, zero-mean Gaussian random variables."

It is no coincidence that, although MBG represents a broad class of statistical models applicable to both estimation and prediction problems, the majority of its applications have focused on prediction. This is evident in many scientific fields where MBG has been used, including global public health, which is the primary application focus in this book. In line with the quote above, for most of the examples considered in this book, the analyses we illustrate aim to use a finite set of locations $x_i$ --- typically corresponding to households or villages --- to make inferences about an observed disease risk surface. Having performed estimation of MBG models in @sec-estimation, we can now carry out spatial prediction to answer critical public health questions, such as identifying hot-spots and cold-spots --- areas of unusually high or low disease risk, respectively --- or determining whether the average prevalence across a region exceeds a predefined policy threshold.

In this chapter, we will explore these issues, beginning with a formal statistical formulation of the spatial prediction problem and a description of the necessary steps for its implementation. We will then demonstrate how spatial prediction is performed when considering predictive targets at both the *pixel-level* and *areal-level*. Finally, we will conclude the chapter by presenting methods for comparing the predictive performance of different models, with some insights into their relative strengths and weaknesses.

## Spatial prediction using geostatistical models {#sec-spat-pred-target}

Let us consider the class of generalized linear geostatistical models (GLGM) as in @sec-geostat-models. In the formulation of prediction problems, the first step consists of defining our predictive target, which we denote as $T(x)$ where $x$ denotes any locations within the study, which is usually not part of the sampled data. For example in the analysis of the riverblindness in Liberia, our interest lies in identifying areas where disease prevalence exceeds 20$\%$, a threshold that use been used in the past to identify areas in need of mass drug administration due to the potential for significant disease burden and transmission [@amazigo2008]. Hence, in this case, disease prevalence corresponds to our predictive target $T(x)$. To draw inferences on $T(x)$ and allow us to answer the question of where $T(x)$ exceeds a 20$\%$ threshold, we first need to obtain the so called *predictive distribution* of $T(x)$. More specifically, the *predictive distribution* of $T(x)$ is the distribution of $T(x)$ conditioned to the data, which we denote by $[T(x) \: \mid \: y]$. More importantly, by incorporating the information provided by the data, the predictive distribution of the target enables us to quantify the uncertainty stemming from the stochastic nature of the process we are modeling. In other words, the predictive distribution reflects the range of possible values that the target $T(x)$ can take and their likelihoods based on the model we have fitted to the data. As we shall see in our examples, we can use the predictive distribution of $T(x)$ both to provide what is our "best guess" for $T(x)$ and a summary of uncertainty which quantifies how much concentrated is the predictive distribution around that guess. However, providing a single "best guess" for $T(x)$ is not always the answer to our research question. In the example on riverblindness mentioned at the start of the this section, a more natural way to use the predictive distribution would be to compute the likelihood that $T(x)$ exceeds 0.2 at any given location $x$.

In summary, the first two steps of spatial prediction are:

-   Step 1. define the predictive target $T(x)$;

-   Step 2. obtain the predictive distribution of $T(x)$ and use this to compute summaries that helps to answer your original research question.

This begs two practical questions: "How do we obtain the predictive distribution of $T(x)$?" and "How do we use the predictive distribution to compute our summaries?". For a mathematical derivation of the predictive distribution and the form that this takes in the special case of a linear geostatistical model, you can read @sec-theory-prediction. In what follows, we shall assume that we can simulate directly from $[T(x) \: \mid \: y]$ either using direct simulation or Markov Chains Monte Carlo (see @sec-mcmc-mala).

In our exposition so far, we have also made the implicit assumption that prediction is required for our predictive target at a single, unsampled, location $x$ and for this reason we have denote our predictive target simply as $T(x)$. However, this is almost never the case, since in most cases, our predictive target correspond to either of the following.

-   **Spatially continuous targets** correspond to an unobserved spatially continuous surface (e.g. disease prevalence), formally denoted by $\mathcal{T} = \{T(x), x \in A\}$, where $A$ is our region of interest.

-   **Areal-level targets**, usually defined as transformation of the spatially continuous surface $\mathcal{T}$, defined previously, and which we denote as $\mathcal{T}_{A} = F(\mathcal{T}, A)$. For example, the average of $T(x)$ over $A$ is an areal-level target, formally defined as $F(\mathcal{T}, A) = \int_{A} T(x) \: dx / |A|$, where $|A|$ is the area of $A$.

Before we consider these two types of prediction targets more in detail, we first explain the preliminary steps that need to be performed and are common to both. Whether our goal is predict a spatially continuous or areal-level target, the initial task is to draw Monte Carlo samples from the predictive distribution of the spatial process $S(x)$[^05_geostatistical-prediction-1]. Next, we define a set of prediction locations, say $q$ in total, denoted as $\tilde{X} = {\tilde{x}_1, \ldots, \tilde{x}_q}$. These locations correspond to a regular grid that spans our region of interest, $A$. the predictive distribution of the spatial process over the grid, represented as $[S(\tilde{X}) \: |\: y]$. This distribution allows us to generate Monte Carlo samples for $S(\tilde{X})$, which will later be used for computing our target.

[^05_geostatistical-prediction-1]: Here, we are overlooking the fact that when $T(x)$ is a linear transformation of $S(x)$ and the the model fitted to the data is a linear geostatistical model, then we can derive any summary of the predictive distribution analytically, without the need of carrying out any simulation. Although this may displease some of our fellow statisticians who care about computational efficiency, for pedagogical reasons, here we have chosen to explain only the Monte Carlo based approach, which works in all scenarios.

At this stage, we need to consider which of the two following types of predictions from $[S(\tilde{X}) \: |\: y]$ are required.

-   **Marginal predictions** are obtained by simulating independently from the $q$ marginal predictive distributions of $[S(\tilde{X}) | y]$. In other words, we consider a prediction location $\tilde{x}_j$, simulate from $[S(\tilde{x}_j) \: |\: y]$ say $B$ samples, and repeat this for $j=1,\ldots,q$

-   **Joint predictions** are obtained by simulating from the joint distribution of $[S(\tilde{X}) \: |\: y]$. Unlike marginal predictions, joint predictions take into account the correlation between the different components of $[S(\tilde{X}) \: |\: y]$.

To better understand the technical differences between marginal and joint predictions, we refer you to @sec-pred-distr-theory. However, in practice, the two following facts are important.

-   *Fact 1*. Joint predictions are computationally more intensive than marginal predictions.

-   *Fact 2*. Joint predictions are required when the predictive target is at areal-level.

-   *Fact 3*. For spatially continuous targets, both marginal and joint predictions can be used but, in light of *Fact 1*, we might prefer using the former.

### Generating samples from the predictive distribution of $S(\tilde{X})$ (continue from @sec-liberia-estim1) {#sec-pred-samples}

We now show how the ideas and concepts discussed above are put into practice in an geostatistical analysis, using the Liberia data example. Using the fitted model in @sec-liberia-estim1, we use the `predict_over_grid` function in `RiskMap`, to sample from the predictive distribution of the spatial Gaussian process $S(x)$ based on a regular grid spanning the country of Liberia.

The `pred_over_grid` function enables us to predict the the separate effects of the covariates, given by $d(x)^\top \beta$, and the spatial random effects, $S(x)$, at any desired location $x$. Hence, before we can use the `pred_over_grid` function, we need to do 1) obtain a shape file that defines the boundaries of our study area, 2) use that to create a regular grid and 3) extract the covariates values at those locations. The R script below performs all these steps.

```{r, echo=FALSE, message=FALSE, collapse=TRUE}
library(sf)
library(RiskMap)
library(ggplot2)
load("./data/fit_liberia.RData")
data("malkenya")
malkenya_comm <- malkenya[malkenya$Survey=="community", ]
load("./data/fit_malkenya.RData")
load("./data/pred_age15.RData")
load("./data/pred_aver_pop.RData")
load("./data/lb_pred_S_m.RData")
load("./data/lb_pred_S_j.RData")
liberia_grid <- lb_pred_S_j$grid_pred
load("./data/an_fit.RData")

load("data/pred_shp.RData")
load("data/pred_shp_w.RData")
```

```{r, collapse = TRUE, message=FALSE}
# 1) Obtaining Liberia boundaries 
library(rgeoboundaries)
liberia_adm0 <- geoboundaries("liberia", adm_lvl = "adm0")
liberia_adm0 <- st_transform(liberia_adm0, crs = 32629)

# 2) Create the grid at 5 km resolution
liberia_grid <- create_grid(liberia_adm0, spat_res = 5)

# Download elevation data
library(elevatr)
liberia_elev <- get_elev_raster(locations = liberia_adm0, 
                                z = 5, clip = "locations")

# 3) Extracting elevation at the grid locations
lb_predictors <- data.frame(elevation = 
                         terra::extract(liberia_elev,
                                st_coordinates(liberia_grid)))
```

In the code above, we generated a prediction grid --- which, we recall, that we denote as $\tilde{X}$ --- with a spatial resolution of 5 km. Generally, a higher spatial resolution (note that a "higher spatial resolution" corresponds to a lower value for `spat_res`) yields more detailed prediction maps but also increases the computational cost. In this case, the choice of a 5 km grid strikes a balance between sufficient visualization clarity and manageable computation time.

At this point, we have all the necessary inputs to execute the `pred_over_grid` function for both marginal and joint predictions, as demonstrated below.

```{r, eval = FALSE}
# Predicting the spatial process S(x) over the grid, as well as
# covariates effects

# Marginal predictions
lb_pred_S_m <- pred_over_grid(fit_liberia, 
                            grid_pred = liberia_grid, 
               predictors = lb_predictors, messages = FALSE,
               type = "marginal")

# Joint predictions
lb_pred_S_j <- pred_over_grid(fit_liberia, 
                            grid_pred = liberia_grid, 
               predictors = lb_predictors, messages = FALSE,
               type = "joint")
```

Both `lb_pred_S_m` and `lb_pred_S_j` contain lists with the same arguments, with one key difference: the samples in the list element named `S_samples` for the former are drawn from the marginal predictive distributions of the components of $S(\tilde{X})$, while for the latter, they come from the joint predictive distribution of $S(\tilde{X})$.

An important note is that in the code above we have used the default settings for the Markov Chain Monte Carlo (MCMC). To change these setting use the function `set_control_sim` whose output should be passed to the argument `contol_sim` of `pred_over_grid`. The diagnostic on the convergence of the MCMC can also be applying the `check_mcmc` function to either `lb_pred_S_m` or `lb_pred_S_j`; see @sec-summary for more details.

We can inspect the predictive distribution of any component $S(\tilde{X})$ through the Monte Carlo samples stored in `S_samples`. For example, the script below generates the histogram for the predictive distribution of the first component of $S(\tilde{X})$ (@fig-hist-first-comp-pd).

```{r}
#| label: fig-hist-first-comp-pd
#| fig-cap: "Histrogram of the predictive distribution of the first component, $S(\\tilde{x}_1)$ of $S(\\tilde{X})$ for the Liberia data analysis."

hist(lb_pred_S_m$S_samples[,1], main = "Predictive distribution",
     xlab = expression(S(tilde(x)[1])))
```

## Spatially continuous targets

In the previous section, we explained and demonstrated how to obtain Monte Carlo samples from the predictive distribution of $S(\tilde{X})$, which we denoted by $[S(\tilde{X}) \: |\: y]$. Let $S_{(j)}(\tilde{X})$ and $[S(\tilde{X}) \: |\: y]$ represent the $j$-th Monte Carlo samples for the entire grid and the specific location $x_k$, respectively, for $j=1,\ldots,B$ and $k=1,\ldots,q$.

We define our predictive target, $T(x)$, at any given location $x$, as a transformation of $S(x)$. Thus, we express it as $T(x) = f\{S(x)\}$. Note that $f(\cdot)$ can represent any type of non-linear transformation of $S(x)$ and may include covariate effects and other non-structured random effects. A list of common predictive targets frequently used in geostatistical analysis is provided in @tbl-spat-cont-pred-target.

| Predictive target $T(x)$                                                  | Name of the predictive target | Generalized linear model (GLM) family |
|----------------------------|----------------------|-----------------------|
| $d(x)^\top \beta + S(x)$                                                  | Linear predictor              | Any GLM                               |
| $\frac{\exp\{d(x)^\top \beta + S(x)\}}{1+\exp\{d(x)^\top \beta + S(x)\}}$ | Prevalence                    | Binomial                              |
| $\exp\{d(x)^\top \beta + S(x)\}$                                          | Mean number of cases          | Poisson                               |
| $S(x)$                                                                    | Spatial random effects        | Any GLM                               |
| $d(x)^\top \beta$                                                         | Covariates effects            | Any GLM                               |

: List of some of the most common spatially continuous predictive targets in a geostatistical analysis. For each target, we also indicate the generalized linear model (GLM) family for which these can be defined. Note that this list not exhaustive and different predictive other than those listed in the table could also be considered. {#tbl-spat-cont-pred-target}

An important feature of the predictive targets listed in @tbl-spat-cont-pred-target is that none of them include the nugget effect, denoted by $Z_i$ in our linear predictor definition for generalized linear geostatistical models. The reason for excluding $Z_i$ from the predictive targets is that, in most cases, it lacks a clear, unambiguous scientific interpretation. However, $Z_i$ might be included, for example, in environmental studies focusing on highly localized phenomena where measurement error or small-scale variability is of direct scientific interest; or in epidemiological studies where inferences at the individual level, rather than the population level, are required, and where $Z_i$ is introduced to account for unexplained individual-level variation. It is also worth noticing, the primary impact of including $Z_i$ in $T(x)$ would be an increase in the uncertainty of predictive inferences for $T(x)$, with minimal effect (or none at all, if $T(x)$ corresponds to the linear predictor) on the point predictions.

The predictive targets in @tbl-spat-cont-pred-target corresponding to $d(x)^\top \beta$ or the spatial random effects $S(x)$ might be considered when the goal is to highlight the different contribution to the overall predictive inferences from the measured covariates.

### Example: mapping riverblidness prevalence in Liberia (continuing from @sec-pred-samples) {#sec-liberia-prediction-1}

Let us continue the geostatistical of the riverblindness data in Liberia. The predictive target we consider is prevalence, hence $$T(x) = \frac{\exp\{ \beta_{0} + \beta_{1}\log\{e(x)\} + S(x)\}}{1+\exp\{\beta_{0} + \beta_{1}\log\{e(x)\} + S(x)\}},$$ {#eq-rb-prev-target} where $e(x)$ is the elevation in meters at location $x$.

Through the `pred_target_grid` we can use the output in `lb_pred_S_m` (or `lb_pred_S_j` as well, in this case) to generate predictions of prevalence over the regular grid at 5 km we have created earlier.

```{r, collapse=TRUE}

# Prediction of riverblindness prevalence
lb_prev <- 
pred_target_grid(
  lb_pred_S_m, 
  f_target = list(prev = function(lp) exp(lp)/(1+exp(lp))),
  pd_summary = list(mean = function(Tx) mean(Tx), 
                    cv = function(Tx) sd(Tx)/ mean(Tx),
                    exceed20 = function(Tx) mean(Tx > 0.2))
)
```

In the function above the argument `f_target` can take a list of functions, as multiple predictive targets can be defined. Here, we only specified prevalence (`prev`). Note that in defining the predictive target in `f_target`, we need to express that as a function of $d(x)^\top \beta + S(x)$. The argument `include_covariates` also allows us to define predictive target that do not use covariates from the model. By default `include_covariates = TRUE`, hence in the code above covariates are part of what is defined as `lp`. To predict the spatial random effects $S(x)$ only, for example, you can set `include_covariates = FALSE` and `f_target = list(Sx = function(lp) lp)`. In `pd_summary`, we define the summaries that we want to visualize from the predictive distribution. Here, we have specified the mean, coefficient of variation and the probability of exceeding a 20$\%$ prevalence threshold.

We can then visualize the resulting maps as follows.

```{r, collapse=TRUE}
#| label: fig-lb-maps
#| fig-cap: "Mapping riverblindness in Liberia. Plots of the mean (left panel), coefficient of variation (central panel) and exceedance probability (right panel) for a 20% prevalence threshold."

# Displying the results
par(mfrow = c(1,3))
plot(lb_prev, which_target = "prev", 
     which_summary = "mean", main = "Mean")
plot(lb_prev, which_target = "prev", 
     which_summary = "cv", main = "Coefficient of variation")
plot(lb_prev, which_target = "prev", 
     which_summary = "exceed20", main = "Exceedance probability")
par(mfrow=c(1,1))
```

The maps in @fig-lb-maps indicate a higher prevalence as we move away from the coast and at higher altitudes. A very similar spatial pattern is observed in the likelihood of exceeding 20$\%$ prevalence. Also, based on the map of the coefficient of variation, the uncertainty around the point predictions of prevalence is higher along the coast and lower in the inland areas of Liberia.

### Example: mapping malaria using age and elevation as predictors {#sec-non-spar-covariates}

We now consider an example on malaria mapping, where we use two different types of covariates: a spatially referenced covariate corresponding to elevation; the individual age. We use the `malkenya_comm` subset of the `malkenya` data-set (see @sec-indiv-expl-analysis) and, to alleviate the computational burden, we further reduce this data-set by taking the first 1000 rows. Hence, we create our new data-set, `malkenya_comm1000`, using the followind code.

```{r, collapse=TRUE}
malkenya_comm1000 <- malkenya_comm[1:1000,]

malkenya_comm1000 <- st_as_sf(malkenya_comm1000, coords = c("Long", "Lat"),
                              crs = 4326)
malkenya_comm1000 <- st_transform(malkenya_comm1000, crs = 32736)
```

Based on the exploratory analysis shown in @sec-indiv-expl-analysis, we consider a geostatistical model fitted to the individual binary outcomes, $Y_{ij}$, which correspond the rapid diagnostic test (RDT) results for the $j$-th individual in the $i$-th community, and take value $Y_{ij}=1$ if the RDT is positive and $Y_{ij}=0$ if the RDT is negative. Using a Binomial geostatistical model, we model the individual probability, $p_{ij}$ of a positive RDT using the following linear predictor. $$
\log\left\{\frac{p_{ij}}{1-p_{ij}}\right\} = \beta_{0} + \beta_{1}a_{ij}+\beta_{2} \times\max\{a_{ij}-15, 0\} + \beta_{3}\max\{a_{ij}-40, 0\} + \beta_{4} e(x_i) + S(x_i),
$$ {#eq-lp-malkenya} where $e(x_{i})$ and $a_{ij}$ are the elevation in meter and the age in years for the $j$-th individual residing at the $i$-th household, respectively.

When using the model in @eq-lp-malkenya to predict RDT prevalence, a key question arises: how should we handle the age variable, which, unlike elevation, is not available as a geo-referenced covariate at all locations in the study area? The answer depends on the research question being addressed.

For instance, if the goal is to infer disease risk across different age groups, we can generate different maps for each group of interest. This can be easily achieved by fixing the value of $a_{ij}$ to a specific age for all prediction locations. Alternatively, if the objective is to generate a predictive map for the general population, rather than for a specific age group, we must employ a probabilistic model for age and integrate out its effect.

Developing a credible probabilistic model for age is beyond the scope of this section. Instead, we demonstrate a simple yet reasonable solution which uses the empirical age distribution from the data. By random sampling from this distribution, we can then assign age values to prediction locations. The steps are as follows.

1.  Obtain the empirical distribution of age from the data.
2.  Sample with replacement from such distribution (the `sample` function in R can be used for this purpose) as many times as the number of prediction locations, so that each grid location $\tilde{x}$ has a value of age assigned.
3.  Generate a sample from the predictive distribution of the target $T(\tilde{x})$ at each of the grid locations $\tilde{x}$.
4.  Repeat 1 to 3, for as many times as the samples generates from $S(\tilde{X})$.

This approach relies on two key assumptions. First, that the age distribution is spatially neutral, i.e., it does not vary across space. Second, that the data are representative of the age distribution in the target population. In the data used for this example, we believe these assumptions are reasonable, given the relatively small study area, where age is unlikely to exhibit significant spatial variation, and the fact that the data are a random sample from the community.

In the scripts presented in the remainder of this section, we show how to generate a predictive map of prevalence for children age 15 years, and another map that instead uses the approach earlier described to remove the effect of age and generate a map of prevalence for the general population.

First, we fit the model. Note that the effect of age is not linear and we use linear splines to account for this, using the results of the exploratory analysis shown in \@@sec-indiv-expl-analysis.

```{r, eval=FALSE}
fit_malkenya <- glgpm(RDT ~ Age +  pmax(Age-15, 0) + 
                        pmax(Age-40, 0) + elevation +
                        gp(),
                      data = malkenya_comm1000,
                      family = "binomial")
```

After fitting the model, we create a prediction grid at a spatial resolution of 500 meters and extract the values of elevation. In this analysis, due to the small size of the study area, we do not use administrative boundaries as they are too large. Instead, we use the convex hull[^05_geostatistical-prediction-2] of the sample locations to define the boundaries of our study area.

[^05_geostatistical-prediction-2]: The convex hull of a set of spatial locations is the smallest possible shape (usually a polygon) that completely encloses all the points, such that if you take any two points inside the shape, the straight line connecting them is also entirely inside the shape. In simple terms, it can be thought of as stretching a rubber band around the outermost points in a set, and the shape the rubber band forms is the convex hull.

```{r, eval=FALSE}

# Create grid from convex hull
shp_ch <- convex_hull_sf(malkenya_comm1000)
ken_grid <- create_grid(shp_ch, spat_res = 0.5)

# Get elevation raster
ken_elev <- 
get_elev_raster(locations = shp_ch, 
                z = 9, clip = "locations")
```

We then create the data frame of predictors where age is set to 15.

```{r,eval=FALSE}
# Create the data fr
ken_predictors <- data.frame(elevation = 
                           extract(ken_elev, st_coordinates(ken_grid)),
                         Age = 15)
```

We now have all the ingredients to carry out prediction.

```{r, eval=FALSE}
pred_ken_S <- pred_over_grid(fit_malkenya, grid_pred = ken_grid,
                             predictors = ken_predictors)

pred_age15 <- 
pred_target_grid(pred_ken_S, 
                 f_target = list(prev = function(lp) exp(lp)/(1+exp(lp))),
                 pd_summary = list(mean = function(Tx) mean(Tx)))
```

The code below shows how to perform the 4 steps described above to generate a predictive map for the general population. Below we use the function `update_predictors` to update the covariates effects that are stored in `mu_pred`, a list element generated as the output of `pred_over_grid`.

```{r, eval=FALSE}
# Number of Monte Carlo samples
n_sim <- ncol(pred_age15$lp_samples)

# Number of prediction locations
n_pred <- nrow(predictors)

# The create object `pred_ken_S_i` with the goal of changing the 
# coviariates effects stored in `mu_pred` according the sample values of age
pred_ken_S_i <- pred_ken_S
pred_ken_S_i$mu_pred <- matrix(NA, nrow = n_pred, ncol = n_sim)

for(i in 1:n_sim) {
  # Generate n_pred samples from the empirical distribution of age
  ken_predictors$Age <- sample(malkenya_comm1000$Age, n_pred, replace = TRUE)
  # Generate the new covariates effects with `update_predictors` and store them in 
  # `mu_pred`
  pred_ken_S_i$mu_pred[,i] <- update_predictors(pred_ken_S, ken_predictors)$mu_pred
}

# Prediction of prevalence
pred_aver_pop <- pred_target_grid(pred_ken_S_i, 
               f_target = list(prev = function(lp) exp(lp)/(1+exp(lp))))
```

We can now plot the two maps and compare them.

```{r, collapse=TRUE}
#| label: fig-malaria-maps
#| fig-cap: "Maps of the predictive mean of the rapid diagnostic test (RDT) prevalence for
#| children of the age of 15 (left panel) and the general population (right panel)."
par(mfrow = c(1,2))
plot(pred_age15, which_target = "prev", which_summary = "mean", main = "Prevalence (15 years)", range = c(0,0.6))
plot(pred_aver_pop, which_target = "prev", which_summary = "mean",  main = "Prevalence (General population)", range = c(0,0.6))
par(mfrow = c(1,1))
```

The exploratory analysis of @sec-indiv-expl-analysis had shown that the prevalence around the age of 15 is higher than at other ages. This is also reflected in @fig-malaria-maps, when the left panel, corresponding to the RDT prevalence for children at the age of 15 years, shows a higher level of prevalence than the right panel, which is instead for the general population.

## Areal-level targets

When determining areal-level targets, we must first address the following questions:

1.  What spatially continuous target, $T(x)$, are we seeking to aggregate?
2.  What are the spatial units, denoted as $A_i$ for $i = 1, \dots, N$, over which the aggregation is required?
3.  What aggregating function should be applied?
4.  Should spatial weights be incorporated in the aggregation, and if so, what weights are appropriate?

The first question was discussed in earlier sections, where examples of predictive targets that define $T(x)$ can be found in @tbl-spat-cont-pred-target. The answers to the remaining questions are context-dependent and closely linked to the primary research objectives. In public health settings, the areas $A_i$ often correspond to administrative units or regions where decisions are made and resources are allocated.

A common aggregating function for $T(x)$ is the mean, which is formally defined as:

$$
\mathcal{M}_i = \frac{1}{|A_i|}\int_{A_i} T(x) \: dx.
$$ {#eq-mean-alt}

In addition to the mean, several other aggregating functions can be applied depending on the context of the analysis. We also note that computing the integral in @eq-mean-alt requires some approximations. Our approach utilizes the regular grid $\tilde{X}$, previously defined when dealing with spatially continuous targets. This grid covers the area $A_i$, allowing us to approximate $M_i$ as: $$\mathcal{M}_i \approx \frac{1}{\#\{j : \tilde{x}_j \in A_i\}} \sum_{\tilde{x}_j \in A_i} T(\tilde{x}_j), $$ {#eq-mean-alt-approx} where $\#\{j : \tilde{x}_j \in A_i\}$ denotes the number of grid locations $\tilde{x}_j$ that fall within $A_i$. The same approximation will be applied to other areal-level targets discussed in this section. However, for simplicity, we will omit the detailed explanation of this step and instead express the predictive target as an integral.

For instance, in the study of Anopheles mosquitoes in Cameroon, we may be interested in estimating the total number of mosquitoes trapped within the study area ($A_i$ represents a single region in this case). If $T(x)$ denotes the number of mosquitoes trapped at location $x$, the areal-level target can be expressed as: $$
  \mathcal{S}_i = \int_{A_i} T(x) \: dx.
  $$

Additionally, to capture the heterogeneity of $T(x)$ within an area, variance-based measures can be used. The variance of $T(x)$ in $A_i$ is given by: $$
   \mathcal{V}_i = \frac{1}{|A_i|}\int_{A_i} \left(T(x) - \mathcal{M}_i\right)^2 \: dx,
   $$ where $\mathcal{M}_i$ is the mean of $T(x)$ in $A_i$.

The formulation of the areal-level targets given so far assumes equal weighting for all locations within the area. Alternatively, if the we consider for example the areal level target in @eq-mean-alt, one could use spatial weights, $w(x) > 0$, and redefine $\mathcal{M}_i$ as:

$$
\mathcal{M}_i = \frac{\int_{A_i} w(x) T(x) \: dx}{\int_{A_i} w(x) \: dx}.
$$

Selecting appropriate spatial weights is crucial, as it reflects the significance of different locations within the area. We can define three types of weighting: population-density, risk-based, and distance-based. We point out that this distinction is not always clear cut (population could indeed be a risk factor in our analysis) but this classification is made only for the sake of making the explanation clearer.

For example, if the goal is to prioritize areas with higher populations, weights $w(x)$ could be proportional to population density at location $x$. This approach gives greater importance to locations where more people reside, which can be particularly relevant when aggregating disease prevalence data for resource allocation.

In cases where certain sub-regions within $A_i$ are at higher risk for disease (e.g., proximity to environmental hazards or areas with lower access to healthcare), risk-based weights could be applied. Here, $w(x)$ would be higher in regions identified as higher risk, providing a more targeted aggregation of disease prevalence. For example, populations in rural areas may face higher exposure to infectious diseases than those in urban areas, making it important to assign greater weight to these higher-risk regions in the aggregation process.

If the objective is to account for proximity effects (such as the spread of an infectious disease or contamination from a known source), distance-based weights could be used. Locations closer to a known disease outbreak area or source of exposure could be given more weight to reflect the spatial dynamics of disease transmission.

Using spatial weights in these ways ensures that the aggregation of disease prevalence $T(x)$ reflects not only the distribution of the disease but also the underlying population, risk, or spatial characteristics relevant to the public health problem under investigation.

### Example: predicting the average riverblindness prevalence at admin level 1 in Liberia (continuing from @sec-liberia-prediction-1) {#sec-liberia-prediction-2}

We continue our analysis of the Liberia data and consider areal-level targets. More specifically, we aim to predict the average prevalence over the regions which give the administrative level 1 of Liberia. By denoting with $A_i$ the i-th out of the 15 regions in Liberia. By denoting with $T(x)$ reiverblindness prevalence as defined in @eq-rb-prev-target, we define our predictive target as $$
T_{i} = \frac{1}{|A_i|} \int_{A_i} T(x) \: dx.
$$ The R code below shows how predictions for $T_i$ can be performed using the `pred_target_shp` function.

```{r, collapse=TRUE, message=FALSE, eval=FALSE}
# Admin level 1 boundaries
library(rgeoboundaries)
lb_adm1 <- geoboundaries(country = "Liberia", adm_lvl = "adm1")

# Prediction of prevalence 
pred_shp <- pred_target_shp(lb_pred_S_j, shp = lb_adm1,
                            shp_target = function(Tx) mean(Tx),
                            f_target = list(prev = 
                                       function(lp) exp(lp)/(1+exp(lp))),
                            pd_summary = list(mean = mean),
                            col_names = "shapeName")


```

The argument `shp_target` is used define the type of aggregation function over the region $A_i$, in this case the mean of the target $T(x)$. Also note that, like for spatially continuous targets, we can define any summary of the predictive distribution of $\mathcal{M}_i$ through the argument `pd_summary`. Here, we chose to compute only the mean of the predictive distribution but other summaries, such as exceedance probabilities, standard error, quantiles and so on, can be specified if needed.

Before we plot the results on a map, let us also consider the population-density weighted target, defined as $$
T_{i}^* = \frac{ \int_{A_i} w(x) T(x) \: dx}{\int_{A_i} w(x) \: dx}.
$$ To aid the explanation of the R code script, we first rewrite the above areal-level target as $$
T_{i}^* = \int_{A_i} \tilde{w_i}(x) T(x) \: dx.
$$ where $\tilde{w}_{i}(x)$ are the standardized weights that integrate to 1 in $A_i$ (i.e. $\int_{A_i} \tilde{w}_i(x) \: dx = 1$).

We first retrieve the population density data from the World Pop database (see @sec-pop-data) and use these to derive the un-standardized weights $w(x)$.

```{r, collapse=TRUE, message=FALSE, eval=FALSE}

# Obtaining population density
library(wpgpDownloadR)
lbr_url <- wpgpGetCountryDataset(ISO3 = "LBR", covariate = "ppp_2014")
library(terra)
lbr_pop <- rast(lbr_url)
lbr_pop <- project(lbr_pop, "EPSG:32629")

# Extra pop density weights at the prediction grid
weights_pred <- extract(lbr_pop, st_coordinates(liberia_grid))$lbr_ppp_2014
```

In the code above the population density weights are extracted at the locations of the prediction grid. In the `pred_target_shp` function, in order to use the weights for our predictive target, we need to specify two additional arguments: `weights` to which we pass the population density values (in our case these are stored in `weights_pred`); `standardize_weights`, which is a logical argument taking value `TRUE` if the weights to be standardized so that the sum over the grid covering a region $A_i$ adds up to one.

```{r, collapse=TRUE, eval=FALSE}
pred_shp_w <- pred_target_shp(lb_pred_S_j, shp = lb_adm1,
                            shp_target = function(Tx) sum(Tx),
                            f_target = list(prev = 
                                       function(lp) exp(lp)/(1+exp(lp))),
                            pd_summary = list(mean = mean),
                            weights = weights_pred,
                            standardize_weights = TRUE,
                            col_names = "shapeName")
```

We can then finally plot the results from the prediction at admin level 1, without using any weights and by weighing according to population density.

```{r, collapse=TRUE}
#| label: fig-average-prev-Liberia
#| fig-cap: "Maps of the predictive mean for the admin level 1 average prevalence in Liberia. The left panel uses a standard average of locations within an admin level 1 region, whilst in the right panel each location is weighted according to population density."
plot_1 <- 
plot(pred_shp, which_target = "prev", which_summary = "mean",
     palette = "RdYlGn",
    limits = c(0.1, 0.30),
    breaks = seq(0.1,0.30, by = 0.05)) + 
  guides(fill=guide_legend(title="Prevalence")) +
  ggtitle("Average prevalence \n (no weights)") + 
   theme(plot.title = element_text(size = 15))

plot_2  <- 
  plot(pred_shp_w, which_target = "prev", which_summary = "mean",
     palette = "RdYlGn",
    limits = c(0.1, 0.30),
    breaks = seq(0.1,0.30, by = 0.05)) + 
  guides(fill=guide_legend(title="Prevalence")) +
  ggtitle("Average prevalence \n (population weighted)") + 
  theme(plot.title = element_text(size = 15))

library(gridExtra)
grid.arrange(plot_1, plot_2, ncol = 2)
```

In @fig-average-prev-Liberia, we observe that the differences between the two predictive targets, with and without weights, are not substantial. However, we observe that the predicted average prevalence shows slightly greater variation in coastal regions, particularly in Montserrado County, where the majority of the population residing in the capital of Monrovia. This concentration of population likely accounts for the more noticeable differences in this area.

### Example: predicting the total number of Anopheles gambiae mosquitoes (continuing from @sec-anopheles-fit) {#sec-anopheles-pred}

For the analysis on Anopheles gambiae mosquitoes, we consider the prediction of the total number of mosquitoes within the study area. In this case, because there is not a natural definition of the study area borders as in the previous analysis, we consider the convex hull as representing those borders. To pursue this let us first, visualize the predictive map of the number of mosquitoes on a regular grid cover the study area. In other words, we first consider the spatially continuous target $$
T(x) = \exp\{\beta_0 + \beta_1 e(x) + S(x)\},
$$ where, we recall, $e(x)$ is the elevation in meters at location $x$. In the code below in addition to generate prediction for $T(x)$, we also create a binary indicator defined as $$
w(x) = 
\begin{cases}
1 & \text{if  } 390 < e(x) < 837 \\
0 & \text{otherwise.}
\end{cases}
$$ The values of 390 and 837 meters correspond to the minimum and maximum values of elevation observed in the data.

```{r, message=FALSE, collapse=TRUE}
# Create grid from convex hull
shp_ch <- convex_hull_sf(an_fit$data_sf)
an_grid <- create_grid(shp_ch, spat_res = 2)


an_elev <- get_elev_raster(locations = shp_ch, 
                                z = 9, clip = "locations")

predictors <- data.frame(elevation= terra::extract(an_elev,
                                                   st_coordinates(an_grid)))

pred_an_S <- pred_over_grid(an_fit, grid = an_grid, 
               predictors = predictors,
               type = "joint")

pred_n_mosq_grid <- 
pred_target_grid(pred_an_S, 
                 f_target = list(n_mosq = function(lp) exp(lp)),
                 pd_summary = list(mean = function(Tx) mean(Tx)))

an_weights <- 1*(predictors$elevation > 390 & predictors$elevation < 837)
```

We now define our predictive target corresponding to the total number of mosquitoes within the study area $A$, given by the convex hull of the observed locations, as $$
T = \int_{A} w(x) T(x) \: dx
$$ {#eq-tot-mosq} The rationale is to estimate the total number of mosquitoes in the study area while restricting predictions to locations within the observed range of elevation. This approach helps avoid the risk of predicting in ecological areas that may not be suitable for mosquito presence. It is also important to note that in @eq-tot-mosq, we do not standardize the weights in this case.

```{r, collapse=TRUE}
#| label: fig-mosq-map
#| fig-cap: "Maps of the predicted averae number of mosqutoes (left panel). The right panel shows prediction locations in red if they have an elevation between 390 and 837 meters, or black otherwise.  "
par(mfrow = c(1,2))
plot(pred_n_mosq_grid, which_target = "n_mosq", which_summary = "mean",
     main = "Number of mosquitoes")
plot(an_grid, pch = 20, cex = 1, col = an_weights+1, main = "Weights")
par(mfrow = c(1,1))
```

@fig-mosq-map shows the prediction map for the number of mosquitoes at each prediction location, indicating a relatively high spatial heterogeneity as was also indicated by the low value for the estimate of the scale of the spatial correction (parameter $\phi$). The right panel, we have an image of the weights $w(x)$, with locations that will not contribute to the prediction of the total number of mosquitoes denoted in black.

```{r, collapse=TRUE}
pred_n_mosq_shp <- 
pred_target_shp(pred_an_S, shp = shp_ch, 
                 weights = an_weights,
                 shp_target = sum,
                 f_target = list(n_mosq = function(lp) exp(lp)),
                 pd_summary = list(mean = function(Tx) mean(Tx),
                                   q025 = function(Tx) quantile(Tx, 0.025),
                                   q075 = function(Tx) quantile(Tx, 0.975)))

pred_n_mosq_shp$target$reg1$n_mosq
```

Since we are not standardizing the weights, there is no need to specify `standardize_weights`, as it is set to `FALSE` by default. In the code above, we printed the mean of the predictive distribution of $T$ along with the 95% prediction interval. The point estimate of approximately 17,719 mosquitoes is likely an underestimate of the total number of Anopheles gambiae in the area, as the trap used to count the mosquitoes may not capture all of them, particularly those outside the immediate trapping zone or those active at different times.

## Simulation-based assessment of predictive performance

### How to simulate from a geostatistical model

Before we discuss more in detail how to perform a simulation study, it is important to understand how data can be simulated from a geostatistical model.

The way we have formulated geostatistical models in @sec-geostat-models provides a hint as to what step should be followed when simulating from a geostatistical model. Using the same notation of @sec-geostat-models, these are the steps.

1.  For a given set of predefined locations $X$ compute the covariance matrix $\Sigma$ with $(i,j)-$th entry $\sigma^2 \rho(u_{ij})$.

2.  Compute the covariates effects $d(x)^\top$ for all the locations in $X$.

3.  Simulate $B$-time from a multivariate Gaussian distribution with mean vector 0 and covariance $\Sigma$ as previously defined. We denote the output form this step as $S_{(j)}(x)$, for $j=1,\ldots,B$.

4.  Compute the linear predictor at each locations of $X$, by adding the covariates effects in 3 to the simulated random effects in 4, hence $g\{\mu_{(j)}(x)\} = d(x)^\top + S_{(j)}(x)$.

Note that before performing the steps above, the values of the model parameters must be fixed. For example, if simulating from a model fitted to the data, the values of the model parameters should be the maximum likelihood estimates. At this point, if the goal is to simulate actual observations for the outcome $Y$ at the locations $X$. Then we need to add the following two steps. 5A. If the nugget term is included in the model then, draw samples $Z_{(j)}$ for each location in $X$ from a Gaussian distribution with mean 0 and variance $\tau^2$. Finally add the simulated values $Z_{(j)}$ to $g\{\mu_{(j)}(x)\}$. 6A. Compute $\mu_{(j)}(x)$ by applying the inverse link function $g^{-1}(\cdot)$ to the samples of the linear predictor previously computed. 7A. Simulate from the distribution of $Y$ given $\mu_{(j)}(x)$, according the chosen model, for $j=1,\ldots,B$.

These steps, from 1 to 7A, have been implemented in the `glgpm_sim` function. For example, using the fitted Binomial geostatistical model from the example on riverblindness in Liberia, we simulate a single data-set as follows

```{r, eval = FALSE}
liberia_sim <- glgpm_sim(n_sim = 1, model_fit = fit_liberia)
```

The output `liberia_sim` is a list with as many components as indicated by `n_sim`. In this this case, we can access the simulated data-set as `liberia_sim[[1]]`. For example, we could refit the same model to the simulated data as

```{r, eval = FALSE}
fit_liberia_sim <- 
glgpm(formula = npos ~ log(elevation) + gp(long, lat, nugget = NULL), 
    data = liberia_sim[[1]], family = "binomial", den = ntest, 
    crs = 32629)
```

Note that if the data's CRS has been converted, the simulated dataset will inherit the new CRS rather than the original. This means that any transformation applied to the CRS before simulation (e.g., from geographic to projected coordinates) will affect the spatial scale and interpretation of the simulated data.

In other cases, as in @sec-sim-assessmen, the locations $X$ correspond to a regular grid and the steps that we want to carry out on completion of step 4 above depend on the objective of the simulation. We explain this more in detail in the next section.

### Setting up and carrying out a simulation study

### Assessessment of threshold-based classification of spatial units using geostatistical models {#sec-sim-assessment}

## Comparing the predictive performance of geostatistical models {#compare-pp}

In this section, we address the problem of identifying the geostatistical model that offers the best predictive performance among a set of candidates. However, we first need a clear definition of predictive performance which can be used to select suitable statistical tools that can be to used to evaluate it. Broadly speaking, predictive performance is defined by how well a model's predictive distribution aligns with observed data. Evaluating predictive performance requires examining two key characteristics of the predictive distribution: *sharpness* and *calibration*.

| Diagnostic/Metric                          | Performance characteristic | Descritpion |
|----------------------------------|----------------------|----------------|
| Probability integral transform (PIT)       | Calibration                |             |
| Nonrandomized PIT                          | Calibration                |             |
| Mean square error                          | Calibration                |             |
| Continuous ranked probability score (CRPS) | Calibration and sharpness  |             |
| Scaled CRPS                                | Calibration and sharpness  |             |

: Summary of the different diagnostic tools and metrics, discussed in this chapter, that are used to assess the predictive performance of a geostatistical model. {#tbl-summary-pp-diag}


### How to split the data for model validation

### Assessing calibration

A model is considered *well-calibrated* if its predictions adequately reflect the true uncertainty of the data. Assessment of a model's calibration can be carried out in several ways. We can examine the agreement between the point predictions, say $\hat{y}\_i$, and the observed outcomes \$y_i \$, commonly referred to as *accuracy*. The mean squared error (MSE), defined as $\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$, is an example of a commonly used metric to evaluate the accuracy of a model. To characterize calibration more fully, it is also essential to quantify the spread of the predictive distributions, which also defines the *precision* of predictions. For example, prediction intervals generated from the predictive distribution for $y_i$ can help assess the precision of a geostatistical model. In summary, a well-calibrated model is both accurate and precise.

Assessment of the calibration of the model should precede the assessment of sharpness, since, as we shall see in the next section, this relies on the model being well-calibrated. The probability integral transform (PIT) was originally proposed by @dawid1984 as a way to assess the calibration of a model. The PIT is based on the simple observation that if we consider a variable $Y$ and apply the transformation $Y^* = F_{Y}(Y)$, where $F_{Y}(\cdot)$ is the cumulative density function (or cumulative distribution if $Y$ is discrete) of $Y$, it then follows that $Y^*$ follows a uniform distribution in the unit interval. The fundamental problem and the reason why statistical modelling exists is that we do not $F_{Y}$ but we would like to propose a model $M$ that we believe adequately approximates $F_{Y}$ with $F_{M}$. The main advantage of using the PIT is that assessment of whether $M$ is well calibrated reduces to assessing whether the transform set of data $F_{M}(y_1), \ldots, F_{M}(y_n)$ follows a uniform distribution. To illustrate this, let us a consider a simple simulated example.

We first create a function that can compute the PIT.

```{r, collapse=TRUE}
# Define a function for the PIT
# F_M is the cumulative density function generated by the adopted model
pit_transform <- function(data, F_M) {
  # Apply the model CDF to the data
  pit_values <- F_M(data)
  return(pit_values)
}
```

We then apply this function to show how the assessment of calibration through the PIT is carried out under two scenarios: 1) $F_{Y}$ is a Gamma distribution with shape 2 and scale parameter 1; 2) $F_{Y}$ is Student's T distribution with 3 degrees of freedom. In each of the two scenarios, we show how the PIT behaves when our model coincides with the the true model (i.e. $F_{M} = F_{Y}$) and when instead our model $M$ is a Gaussian distribution, with mean and variance estimated from the data.

```{r, collapse=TRUE}
#| label: fig-hist-pit
#| fig-cap: "Histograms of the probability integral transform applied to simulated data. The top panels show the histograma of the PIT when the fitted model coincides with the true data generating model. The lower panels show how the PIT histrograms deviate from a uniform distribution. For more details, we refer to main text."

# Generate data from a skewed (gamma) distribution
n <- 1000
shape <- 2
rate <- 1
data_gamma <- rgamma(n, shape = shape, rate = rate)

# Define correct and incorrect model CDFs for gamma data
# Correct CDF
model_cdf_correct_gamma <- function(x) pgamma(x, shape = shape, rate = rate)
# Incorrect CDF: Assume data is normal (wrong model)
model_cdf_incorrect_gamma <- function(x) pnorm(x, mean = mean(data_gamma), sd = sd(data_gamma))

# Compute PIT values for gamma data under both models
pit_correct_gamma <- pit_transform(data_gamma, model_cdf_correct_gamma)
pit_incorrect_gamma <- pit_transform(data_gamma, model_cdf_incorrect_gamma)

# Generate data from a heavy-tailed (t) distribution
df <- 3
data_t <- rt(n, df = df)

# Define correct and incorrect model CDFs for t data
# Correct CDF
model_cdf_correct_t <- function(x) pt(x, df = df)
# Incorrect CDF: Assume data is normal (wrong model)
model_cdf_incorrect_t <- function(x) pnorm(x, mean = mean(data_t), sd = sd(data_t))

# Compute PIT values for t data under both models
pit_correct_t <- pit_transform(data_t, model_cdf_correct_t)
pit_incorrect_t <- pit_transform(data_t, model_cdf_incorrect_t)

# Combine results into a data frame for plotting
df_plot <- data.frame(
  PIT = c(pit_correct_gamma, pit_incorrect_gamma, pit_correct_t, pit_incorrect_t),
  Model = rep(c("Correct Gamma Model", "Incorrect Normal Model for Gamma", 
                "Correct t Model", "Incorrect Normal Model for t"), each = n)
)

# Plot PIT distributions
hist_plot <- ggplot(df_plot, aes(x = PIT)) +
  geom_histogram(aes(y = ..density..), bins = 20, fill = "skyblue", color = "black", alpha = 0.7) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  facet_wrap(~ Model, scales = "free") +
  labs(title = "Probability Integral Transform (PIT) Distributions",
       x = "PIT Values",
       y = "Density") +
  theme_minimal()

# Display the plot
print(hist_plot)
```

In @fig-hist-pit, we assess whether the PIT transformed data follow a uniform distribution if the bars of the histogram are all approximately at the same height as indicated by the dashed line. Our preference to this diagnostic plot, is to use a qq-plot for a uniform distribution as shown below.

```{r, collapse=TRUE}
#| label: fig-qqplot-pit
#| fig-cap: "QQ-plots of the probability integral transform applied to simulated data. The top panels show the histograma of the PIT when the fitted model coincides with the true data generating model. The lower panels show how the PIT qq-plots deviate from a uniform distribution. The red line is the identity line For more details, we refer to main text."
#| 
# QQ plot to check uniformity of PIT values
qq_plot <- ggplot(df_plot, aes(sample = PIT)) +
  stat_qq(distribution = qunif) +
  stat_qq_line(distribution = qunif, color = "red") +
  facet_wrap(~ Model, scales = "free") +
  labs(title = "QQ Plot of PIT Values against Uniform Distribution",
       x = "Theoretical Quantiles (Uniform)",
       y = "Sample Quantiles (PIT Values)") +
  theme_minimal()

# Display both plot
print(qq_plot)
```

In the results of @fig-qqplot-pit, we consider a model well-calibrated if the qq-plot is as close as possible to the identity line. It is clear that in the first case the use of Gaussian distribution is violated by the skewness of the data generated from a Gamma distribution, and in the second scenario by the heavier tail of the Student's T distribution.

In the simulated example, the PIT might seem unnecessary because we can directly assess if the data follow the assumed distribution (Gamma, Gaussian, or Student's T) by comparing empirical and theoretical distributions. In these simple models, including linear Gaussian geostatistical models, the marginal distribution of the data is analytically available, so assessing goodness-of-fit is straightforward.

However, in the case of Binomial and Poisson geostatistical models, the marginal distribution of the data $Y$ -- unconditioned on the spatial random effects $S(x)$ -- cannot be obtained analytically. Specifically, geostatistical models for count data assume that $Y$, conditioned on $S(x)$, follows either a Binomial or Poisson distribution. But once we integrate out $S(x)$ to obtain the marginal (i.e., unconditioned) distribution of $Y$, this distribution is no longer Poisson or Binomial. Instead, it becomes an overdispersed count distribution that lacks a closed-form expression.

In such cases, the PIT becomes valuable for evaluating model adequacy, as it allows for assessing the uniformity of PIT values against the assumed model distribution, even when the marginal distribution is intractable. However, direct application of the PIT raises the issue that the the transformation $F_{Y}(Y)$ does not follow a uniform distribution, because of the discrete nature of the random variable $Y$. Hence, for a given discrete-outcome model $M$, we use a modified version of the PIT, referred to as nonrandomized PIT (henceforth, nPIT), originally proposed by @czado2009, taking the form $$
\text{nPIT}(u,y) = 
\begin{cases} 
0, & u \leq F_{M}(y-1) \\ 
\frac{u - F_{M}(y-1)}{P_x - F_{M}(y-1)}, & F_{M}(y-1) \leq u \leq F_{M}(y) \\ 
1, & u \geq F_{M}(y)
\end{cases}.
$$ We then take the average nPIT over the observed outcomes $y_{1}, \ldots, y_{n}$, hence $$
\text{AnPIT}(u) = \frac{1}{n} \sum_{i=1}^n \text{nPIT}(u, y_{i}). 
$$ Assessment of calibration is then carried out by checking wether the AnPIT is as close as possible to the identity function, i.e. $\text{AnPIT}(u) = u$. Hence, by plotting $\text{AnPIT}(u)$ against $u$, we can consider any deviations from the identity line as evidence that the model is not well-calibrated.

We now illustrate the use of the AnPIT through a simulated example. We simulate data from a negative Binomial distribution, with mean $\lambda = 5$ and dispersion parameter $\alpha = 1/2$, hence $E[Y] = \lambda$ and $\text{Var}[Y] = \lambda \times (1 + \alpha \lambda)$.

```{r, collapse=TRUE}
#| label: fig-anpit
#| fig-cap: "Average nonrandomized Probability Integral Transform (AnPIT) applied to simulated data from a Negative Binomial distribution. The left plot shows the AnPIT when the model is correctly specified. The right panel shows the AnPIT when a Poisson model is instead used. For more details  we refer to the main text."

# Parameters for the Negative Binomial distribution
set.seed(123)
n <- 200                # number of simulations
lambda <- 5             # mean
dispersion <- 0.5       # dispersion parameter
size <- 1 / dispersion  # size parameter for negative binomial

# Simulate data from the Negative Binomial distribution
sim_data_nb <- rnbinom(n, size = size, mu = lambda)

# Define the nonrandomized PIT function
compute_npit <- function(y, u, cdf_func) {
  # Calculate cumulative probabilities F_M(y-1) and F_M(y) using the provided CDF function
  f_y_minus_1 <- cdf_func(y - 1)
  f_y <- cdf_func(y)
  
  # Apply the piecewise formula for nPIT
  if (u <= f_y_minus_1) {
    return(0)
  } else if (u <= f_y) {
    return((u - f_y_minus_1) / (f_y - f_y_minus_1))
  } else {
    return(1)
  }
}

# Generate a sequence of u values from 0 to 1
u_values <- seq(0, 1, length.out = 100)

# Calculate the average nPIT for each u value for both models
AnPIT_nb <- sapply(u_values, function(u) {
  mean(sapply(sim_data_nb, compute_npit, u = u, cdf_func = function(k) pnbinom(k, size = size, mu = lambda)))
})

AnPIT_poisson <- sapply(u_values, function(u) {
  mean(sapply(sim_data_nb, compute_npit, u = u, cdf_func = function(k) ppois(k, lambda = lambda)))
})

# Combine the results into a data frame for plotting
AnPIT_data <- data.frame(
  u = rep(u_values, times = 2),
  AnPIT = c(AnPIT_nb, AnPIT_poisson),
  Model = rep(c("Negative Binomial (correct model)", "Poisson (wrong model)"), each = length(u_values))
)

# Plotting the average nPIT as a function of u for both models
ggplot(AnPIT_data, aes(x = u, y = AnPIT, color = Model)) +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +  # Identity line
  facet_wrap(~ Model) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +  
  xlab("u") +
  ylab("AnPIT") +
  theme_minimal() +
  theme(legend.position = "none")  

```
@fig-anpit shows clear evidence that the Poisson model is not adequately accounting for the overdispersion of the simulated data from the Negative Binomial distribution.

How can we adapt this approach to generalized linear geostatistical models (GLGMs)? The concept is straightforward, though the implementation is less so (but fortunately, we have already done this in `RiskMap`). Essentially, in all relevant equations above, we need to replace $M$ with the predictive distribution of the fitted geostatistical model.

To explain further, suppose we have fitted our model using data $Y^{(1)} = \left( y^{(1)}_{1}, \ldots, y^{(1)}_{n} \right)$, and we want to use another set of data $Y^{(2)} = \left( y^{(2)}_{1}, \ldots, y^{(2)}_{m} \right)$ to assess calibration. Our model $M$in the equations above corresponds to the distribution of $\left[ Y^{(1)} \mid Y^{(2)} \right]$, derived from our geostatistical model. Since its derivation  cannot be done analytically, we use Monte Carlo methods to approximate $\left[ Y^{(1)} \mid Y^{(2)} \right]$. We discuss this in more detail in @sec-theory-prediction. However, the key point here is to understand why we perform this assessment and how to interpret the results.


### Assessing sharpness

Sharpness, the other aspect of predictive performance mentioned above, refers to the concentration or narrowness of the predictive distribution around $y_i$. A sharp predictive distribution has a narrow spread, indicating that the model is highly confident in its predictions. Importantly, sharpness does not depend on how close predictions are to the true values (i.e., it is independent of accuracy). A model with high sharpness will produce predictions with low variance, but this sharpness is only meaningful if the model is well-calibrated, ensuring that the high confidence aligns with observed values. For example, a geostatistical model for disease prevalence mapping that predicts a very tight range of possible prevalence values for a location is producing sharp predictions. However, if the actual prevalence often falls outside this range, then the predictions may be sharp but poorly calibrated, thus limiting the value of quantifying sharpness alone. It is important to distinguish between sharpness and precision, as they are similar but subtly different concepts. When considering precision, we are interested in the reliability of the indicators of uncertainty generated from the predictive distribution, such as ensuring that the nominal coverage of prediction intervals matches the actual coverage. Sharpness, instead, refers strictly to the spread of the predictive distribution without regard to accuracy. In other words, while precision generally describes the reproducibility of model predictions across multiple outcomes $y_i$, sharpness purely reflects the model's spread around its point predictions.

## Theory {#sec-theory-prediction}

### Derivation of the predictive distribution {#sec-pred-distr-theory}

### Scoring rules

## FAQs

-   *What should be the spatial resolution of the grid used for prediction?*

-   *I have covariates with different spatial resolutions. Which spatial resolution should I use?*

-   *My prediction map looks like noise. What could be the error?*

-   *The main goal of my analysis is to carry out predictions of the main outcome. However, can I also use the model to draw inferences on the association between the outcome and the covariates that I have included in the model?*

-   *In my model I have some covariates that are attached to the individual (e.g. age, gender, occupation, etc.). How do I specify them when doing prediction?* <br> Read @sec-non-spar-covariates.

## Review questions

-   What are the steps that needs to taken when performing spatial prediction?
-   Define the predictive distribution of a predictive target and explain how this is used to answer a research question.
-   Distinguish between spatially continuous and areal-level targets, giving at least two examples for each.
-   Explain the difference between marginal and joint predictions, and for which targets each can be used.
-   Define predictive performance in terms of calibration and sharpness. 
- Explain how calibration can be assessed using graphical tools, by distinguishing between continuous and count outcomes.
-   Give examples of metrics that can be used to evaluate calibration and sharpness.

## Exercises

1.  *Parametric bootstrap.* Using the model fitted to the Anopheles gambiae mosquitoes in @sec-anopheles-fit, simulate 1000 data-sets using the `glgpm_sim` function and estimate the model to each of the simulated data-set. Use the resulting 1000 estimates to compute 95$\%$ confidence intervals for each of the model parameters and compare this with the confidence intervals obtained from the model summary.

2. Using the code from @compare-pp, redraw the plot of @fig-anpit by choosing different values for the dispersion parameter of the Negative Binomial distribution. What happens when $\alpha$ is close to 0 and why?

